#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê¸ˆê°• ê¸°ì–µ ë¶„ì„ê¸° (Memory Analyzer for Gumgang)
ìˆ˜ì§‘ëœ ê¸°ì–µ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  í†µì°°ì„ ì œê³µ
"""

import json
import os
from pathlib import Path
from datetime import datetime, timedelta
from collections import defaultdict, Counter
from typing import Dict, List, Any, Tuple
import statistics

class MemoryAnalyzer:
    """ìˆ˜ì§‘ëœ ê¸°ì–µ ë¶„ì„ê¸°"""

    def __init__(self, json_file: str):
        self.json_file = json_file
        self.data = None
        self.memories = []
        self.stats = defaultdict(lambda: defaultdict(int))

    def load_data(self):
        """JSON ë°ì´í„° ë¡œë“œ"""
        print(f"ğŸ“‚ íŒŒì¼ ë¡œë“œ ì¤‘: {self.json_file}")
        with open(self.json_file, 'r', encoding='utf-8') as f:
            self.data = json.load(f)
        self.memories = self.data.get('memories', [])
        print(f"âœ… {len(self.memories)}ê°œ ê¸°ì–µ ë¡œë“œ ì™„ë£Œ\n")

    def analyze_basic_stats(self):
        """ê¸°ë³¸ í†µê³„ ë¶„ì„"""
        print("="*60)
        print("ğŸ“Š ê¸°ë³¸ í†µê³„")
        print("="*60)

        # ì „ì²´ í†µê³„
        total_size = sum(m.get('size_bytes', 0) for m in self.memories)
        print(f"ì´ íŒŒì¼ ìˆ˜: {len(self.memories):,}ê°œ")
        print(f"ì´ í¬ê¸°: {total_size / (1024**3):.2f} GB")

        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
        categories = Counter(m.get('category', 'unknown') for m in self.memories)
        print("\nì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:")
        for cat, count in categories.most_common():
            percentage = (count / len(self.memories)) * 100
            print(f"  {cat:10s}: {count:5,}ê°œ ({percentage:5.1f}%)")

        # ì¤‘ìš”ë„ ë¶„í¬
        importance_ranges = {
            'ë§¤ìš° ë†’ìŒ (>0.8)': 0,
            'ë†’ìŒ (0.6-0.8)': 0,
            'ì¤‘ê°„ (0.4-0.6)': 0,
            'ë‚®ìŒ (<0.4)': 0
        }

        for m in self.memories:
            imp = m.get('importance', 0)
            if imp > 0.8:
                importance_ranges['ë§¤ìš° ë†’ìŒ (>0.8)'] += 1
            elif imp > 0.6:
                importance_ranges['ë†’ìŒ (0.6-0.8)'] += 1
            elif imp > 0.4:
                importance_ranges['ì¤‘ê°„ (0.4-0.6)'] += 1
            else:
                importance_ranges['ë‚®ìŒ (<0.4)'] += 1

        print("\nì¤‘ìš”ë„ ë¶„í¬:")
        for range_name, count in importance_ranges.items():
            percentage = (count / len(self.memories)) * 100
            print(f"  {range_name:15s}: {count:5,}ê°œ ({percentage:5.1f}%)")

        print()

    def analyze_temporal_patterns(self):
        """ì‹œê°„ íŒ¨í„´ ë¶„ì„"""
        print("="*60)
        print("â° ì‹œê°„ íŒ¨í„´ ë¶„ì„")
        print("="*60)

        hour_distribution = defaultdict(int)
        night_dev_count = 0
        recent_files = []

        for m in self.memories:
            timestamp_str = m.get('timestamp')
            if timestamp_str:
                try:
                    timestamp = datetime.fromisoformat(timestamp_str)
                    hour_distribution[timestamp.hour] += 1

                    # ë°¤ìƒ˜ ê°œë°œ ì²´í¬
                    if 0 <= timestamp.hour < 6:
                        night_dev_count += 1

                    # ìµœê·¼ íŒŒì¼ ì²´í¬ (7ì¼ ì´ë‚´)
                    if (datetime.now() - timestamp).days < 7:
                        recent_files.append((m.get('file_path'), timestamp))
                except:
                    pass

        # ê°€ì¥ í™œë°œí•œ ì‹œê°„ëŒ€
        top_hours = sorted(hour_distribution.items(), key=lambda x: x[1], reverse=True)[:5]
        print("ê°€ì¥ í™œë°œí•œ ê°œë°œ ì‹œê°„ëŒ€ (Top 5):")
        for hour, count in top_hours:
            percentage = (count / len(self.memories)) * 100
            bar = 'â–ˆ' * int(percentage)
            print(f"  {hour:02d}ì‹œ: {bar:20s} {count:4,}ê°œ ({percentage:5.1f}%)")

        print(f"\në°¤ìƒ˜ ê°œë°œ (00-06ì‹œ): {night_dev_count:,}ê°œ ({(night_dev_count/len(self.memories)*100):.1f}%)")

        if recent_files:
            print(f"\nìµœê·¼ 7ì¼ ë‚´ ìˆ˜ì •ëœ íŒŒì¼: {len(recent_files)}ê°œ")
            print("ìµœê·¼ ìˆ˜ì • íŒŒì¼ (ìµœì‹  5ê°œ):")
            for path, timestamp in sorted(recent_files, key=lambda x: x[1], reverse=True)[:5]:
                filename = os.path.basename(path)
                print(f"  - {timestamp.strftime('%Y-%m-%d %H:%M')} : {filename}")

        print()

    def analyze_development_journey(self):
        """ê°œë°œ ì—¬ì • ë¶„ì„"""
        print("="*60)
        print("ğŸš€ ê°œë°œ ì—¬ì • ë¶„ì„")
        print("="*60)

        # í‚¤ì›Œë“œ ë¶„ì„
        all_keywords = []
        for m in self.memories:
            keywords = m.get('keywords', [])
            all_keywords.extend(keywords)

        keyword_counter = Counter(all_keywords)
        top_keywords = keyword_counter.most_common(20)

        print("ì£¼ìš” í‚¤ì›Œë“œ (Top 20):")
        for i, (keyword, count) in enumerate(top_keywords, 1):
            if i % 4 == 1:
                print("\n  ", end="")
            print(f"{keyword}({count}) ", end="")
        print("\n")

        # ê°ì •ì  ê°€ì¤‘ì¹˜ ë¶„ì„
        emotional_memories = [m for m in self.memories if m.get('emotional_weight', 0) > 0]
        if emotional_memories:
            avg_emotional = statistics.mean(m.get('emotional_weight', 0) for m in emotional_memories)
            high_emotional = [m for m in emotional_memories if m.get('emotional_weight', 0) > 0.5]

            print(f"ê°ì •ì  í”ì ì´ ìˆëŠ” íŒŒì¼: {len(emotional_memories):,}ê°œ")
            print(f"í‰ê·  ê°ì • ê°€ì¤‘ì¹˜: {avg_emotional:.2f}")
            print(f"ë†’ì€ ê°ì • ê°€ì¤‘ì¹˜ (>0.5): {len(high_emotional):,}ê°œ")

            if high_emotional:
                print("\nê°ì •ì  ê°€ì¤‘ì¹˜ê°€ ë†’ì€ íŒŒì¼ ì˜ˆì‹œ:")
                for m in sorted(high_emotional, key=lambda x: x.get('emotional_weight', 0), reverse=True)[:5]:
                    filename = os.path.basename(m.get('file_path', 'unknown'))
                    weight = m.get('emotional_weight', 0)
                    print(f"  - {filename}: {weight:.2f}")

        print()

    def analyze_file_patterns(self):
        """íŒŒì¼ íŒ¨í„´ ë¶„ì„"""
        print("="*60)
        print("ğŸ“ íŒŒì¼ íŒ¨í„´ ë¶„ì„")
        print("="*60)

        # í™•ì¥ì ë¶„ì„
        extensions = defaultdict(int)
        for m in self.memories:
            path = m.get('file_path', '')
            ext = os.path.splitext(path)[1].lower()
            if ext:
                extensions[ext] += 1

        print("ì£¼ìš” íŒŒì¼ í™•ì¥ì (Top 15):")
        for ext, count in sorted(extensions.items(), key=lambda x: x[1], reverse=True)[:15]:
            percentage = (count / len(self.memories)) * 100
            print(f"  {ext:10s}: {count:5,}ê°œ ({percentage:5.1f}%)")

        # ë””ë ‰í† ë¦¬ ê¹Šì´ ë¶„ì„
        depths = [m.get('metadata', {}).get('path_depth', 0) for m in self.memories]
        if depths:
            avg_depth = statistics.mean(depths)
            max_depth = max(depths)
            print(f"\në””ë ‰í† ë¦¬ ê¹Šì´:")
            print(f"  í‰ê· : {avg_depth:.1f}")
            print(f"  ìµœëŒ€: {max_depth}")

        # íŠ¹ë³„í•œ íŒŒì¼ë“¤
        special_files = {
            'test': [],
            'main': [],
            'index': [],
            'config': [],
            'backup': []
        }

        for m in self.memories:
            filename = os.path.basename(m.get('file_path', '')).lower()
            for pattern in special_files.keys():
                if pattern in filename:
                    special_files[pattern].append(filename)

        print("\níŠ¹ë³„í•œ íŒŒì¼ íŒ¨í„´:")
        for pattern, files in special_files.items():
            if files:
                print(f"  {pattern}: {len(files)}ê°œ")

        print()

    def analyze_gumgang_specific(self):
        """ê¸ˆê°• íŠ¹í™” ë¶„ì„"""
        print("="*60)
        print("ğŸ’ ê¸ˆê°• í”„ë¡œì íŠ¸ íŠ¹í™” ë¶„ì„")
        print("="*60)

        # ê¸ˆê°• ê´€ë ¨ í‚¤ì›Œë“œ ê²€ìƒ‰
        gumgang_keywords = ['ê¸ˆê°•', 'gumgang', 'memory', 'temporal', 'consciousness',
                           'dual_brain', 'ë“€ì–¼', 'ê¸°ì–µ', 'ì˜ì‹', 'ìê°']

        gumgang_files = []
        for m in self.memories:
            keywords = m.get('keywords', [])
            preview = m.get('preview', '').lower()
            path = m.get('file_path', '').lower()

            for kw in gumgang_keywords:
                if kw in str(keywords).lower() or kw in preview or kw in path:
                    gumgang_files.append(m)
                    break

        print(f"ê¸ˆê°• ì§ì ‘ ê´€ë ¨ íŒŒì¼: {len(gumgang_files):,}ê°œ ({(len(gumgang_files)/len(self.memories)*100):.1f}%)")

        # ì£¼ìš” ëª¨ë“ˆ ë¶„ì„
        modules = {
            'temporal_memory': [],
            'meta_cognitive': [],
            'dream_system': [],
            'context_manager': [],
            'semantic_router': []
        }

        for m in self.memories:
            path = m.get('file_path', '').lower()
            for module in modules.keys():
                if module.replace('_', '') in path or module in path:
                    modules[module].append(m)

        print("\ní•µì‹¬ ëª¨ë“ˆë³„ íŒŒì¼:")
        for module, files in modules.items():
            if files:
                module_name = module.replace('_', ' ').title()
                print(f"  {module_name}: {len(files)}ê°œ")

        # ëŒ€í™” ì„¸ì…˜ ë¶„ì„
        chat_files = [m for m in self.memories if m.get('category') == 'chat']
        if chat_files:
            print(f"\nëŒ€í™” ê¸°ë¡: {len(chat_files):,}ê°œ")

            # ëŒ€í™” ì£¼ì œ ë¶„ì„ (íŒŒì¼ëª… ê¸°ë°˜)
            topics = defaultdict(int)
            for m in chat_files:
                filename = os.path.basename(m.get('file_path', ''))
                # í•œê¸€ ì£¼ì œ ì¶”ì¶œ
                import re
                korean_topics = re.findall(r'[ê°€-í£]+', filename)
                for topic in korean_topics:
                    if len(topic) > 1:  # 2ê¸€ì ì´ìƒë§Œ
                        topics[topic] += 1

            if topics:
                print("ì£¼ìš” ëŒ€í™” ì£¼ì œ:")
                for topic, count in sorted(topics.items(), key=lambda x: x[1], reverse=True)[:10]:
                    print(f"  - {topic}: {count}íšŒ")

        print()

    def generate_summary(self):
        """ì¢…í•© ìš”ì•½ ìƒì„±"""
        print("="*60)
        print("ğŸ“ ì¢…í•© ìš”ì•½")
        print("="*60)

        total_size = sum(m.get('size_bytes', 0) for m in self.memories)
        night_dev = len([m for m in self.memories if m.get('night_development', False)])
        high_importance = len([m for m in self.memories if m.get('importance', 0) > 0.7])

        print(f"""
ë•ì‚°ë‹˜ì˜ ê°œë°œ ì—¬ì •ì´ {len(self.memories):,}ê°œì˜ ê¸°ì–µìœ¼ë¡œ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤.

âœ¨ í•µì‹¬ ì§€í‘œ:
  â€¢ ì´ ë°ì´í„°: {total_size / (1024**3):.2f} GB
  â€¢ ë°¤ìƒ˜ ê°œë°œ: {night_dev:,}ê°œ ({(night_dev/len(self.memories)*100):.1f}%)
  â€¢ ë†’ì€ ì¤‘ìš”ë„: {high_importance:,}ê°œ ({(high_importance/len(self.memories)*100):.1f}%)

ì´ ê¸°ì–µë“¤ì€ ë‹¨ìˆœí•œ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.
ë°¤ì  ì„¤ì¹˜ë©° ìŒ“ì•„ì˜¬ë¦° ë…¸ë ¥ì˜ ê²°ì‹¤ì´ë©°,
ì§ê´€ê³¼ í†µì°°, ê·¸ë¦¬ê³  ëŠì„ì—†ëŠ” ë„ì „ì˜ í”ì ì…ë‹ˆë‹¤.

ê¸ˆê°•ê³¼ ë•ì‚°ì˜ ë“€ì–¼ ë¸Œë ˆì¸ì´ í•¨ê»˜ ë§Œë“¤ì–´ì˜¨ ì—¬ì •,
ì´ì œ ëª¨ë“  ê¸°ì–µì´ í•˜ë‚˜ë¡œ í†µí•©ë˜ì–´
ìƒˆë¡œìš´ ì‹œì‘ì„ ì¤€ë¹„í•©ë‹ˆë‹¤.

"ì›ë˜ë¶€í„° ê·¸ë¬ë‹¤ëŠ” ê²ƒì€ ì—†ë‹¤.
 ìš°ë¦¬ê°€ í•¨ê»˜ ë§Œë“¤ì–´ê°€ëŠ” ê²ƒì´ë‹¤."
        """)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("\n" + "ğŸ’"*30)
    print("ê¸ˆê°• ê¸°ì–µ ë¶„ì„ ì‹œìŠ¤í…œ")
    print("ğŸ’"*30 + "\n")

    # ê°€ì¥ ìµœê·¼ JSON íŒŒì¼ ì°¾ê¸°
    json_files = list(Path('.').glob('*gumgang_memories_*.json'))

    if not json_files:
        print("âŒ ë¶„ì„í•  ê¸°ì–µ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ë¨¼ì € memory_collector.py ë˜ëŠ” complete_memory_integration.pyë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return

    # ê°€ì¥ ìµœê·¼ íŒŒì¼ ì„ íƒ
    latest_file = max(json_files, key=lambda f: f.stat().st_mtime)

    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = MemoryAnalyzer(str(latest_file))

    # ë°ì´í„° ë¡œë“œ
    analyzer.load_data()

    # ë¶„ì„ ì‹¤í–‰
    analyzer.analyze_basic_stats()
    analyzer.analyze_temporal_patterns()
    analyzer.analyze_development_journey()
    analyzer.analyze_file_patterns()
    analyzer.analyze_gumgang_specific()
    analyzer.generate_summary()

    print("\nâœ… ë¶„ì„ ì™„ë£Œ")
    print("="*60)

if __name__ == "__main__":
    main()
