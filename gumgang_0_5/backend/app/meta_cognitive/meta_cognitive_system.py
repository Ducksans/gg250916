#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê¸ˆê°• 2.0 ë©”íƒ€ ì¸ì§€ ì‹œìŠ¤í…œ (Meta-Cognitive System)
ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ì˜ ìê¸° ì¸ì‹ AI êµ¬í˜„

Based on Latest Research:
- "Language Models Are Capable of Metacognitive Monitoring and Control" (2024)
- "Think, Reflect, Create: Metacognitive Learning for Zero-Shot Planning" (2024)
- "Large Language Models Have Intrinsic Meta-Cognition" (2024)
- Hierarchical Temporal Memory (HTM) principles from Numenta

í•µì‹¬ í˜ì‹ :
1. ì‹ ê²½ í™œì„±í™” íŒ¨í„´ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
2. ë©”íƒ€ ì¸ì§€ ê³µê°„ ì°¨ì› ì¶•ì†Œ ê¸°ë²•
3. ìê¸° ì„±ì°° ë£¨í”„ (Think-Reflect-Create)
4. í–‰ë™ ìê°€ ì¸ì‹ ë° ë³´ê³ 
5. ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™” ë° ê´€ë¦¬

Author: Gumgang AI Team (Claude 4.1 Think Engine Enhanced)
Version: 3.0
"""

import asyncio
import json
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any, Set, Callable
from dataclasses import dataclass, asdict, field
from collections import defaultdict, deque
from enum import Enum
import logging
from pathlib import Path
import hashlib
import pickle
import threading
from abc import ABC, abstractmethod

# ê¸ˆê°• 4ê³„ì¸µ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì„í¬íŠ¸
from ..core.memory.temporal import (
    get_temporal_memory_system,
    MemoryType,
    MemoryPriority,
    MemoryTrace,
    TemporalMemorySystem
)

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# ========================= ë°ì´í„° í´ë˜ìŠ¤ ì •ì˜ =========================

@dataclass
class NeuralActivation:
    """ì‹ ê²½ í™œì„±í™” íŒ¨í„´ ì¶”ì """
    timestamp: datetime
    layer_name: str
    activation_vector: np.ndarray
    semantic_direction: Optional[str] = None
    variance_explained: float = 0.0
    interpretability_score: float = 0.0

    def magnitude(self) -> float:
        """í™œì„±í™” ê°•ë„ ê³„ì‚°"""
        return np.linalg.norm(self.activation_vector)

    def cosine_similarity(self, other: 'NeuralActivation') -> float:
        """ë‹¤ë¥¸ í™œì„±í™” íŒ¨í„´ê³¼ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„"""
        dot_product = np.dot(self.activation_vector, other.activation_vector)
        norm_product = self.magnitude() * other.magnitude()
        return dot_product / norm_product if norm_product > 0 else 0.0

@dataclass
class CognitiveState:
    """AIì˜ í˜„ì¬ ì¸ì§€ ìƒíƒœ - ì—°êµ¬ ê¸°ë°˜ í™•ì¥"""
    # ê¸°ë³¸ ë©”íŠ¸ë¦­
    confidence_level: float = 0.5  # 0.0-1.0
    processing_load: float = 0.0  # 0.0-1.0
    attention_focus: List[str] = field(default_factory=list)

    # ë©”íƒ€ ì¸ì§€ ë©”íŠ¸ë¦­
    metacognitive_awareness: float = 0.5  # ìê¸° ì¸ì‹ ìˆ˜ì¤€
    learning_efficiency: float = 0.5  # í•™ìŠµ íš¨ìœ¨ì„±
    creativity_level: float = 0.3  # ì°½ì˜ì„± ìˆ˜ì¤€

    # ë¶ˆí™•ì‹¤ì„± ê´€ë¦¬
    uncertainty_areas: List[Dict[str, float]] = field(default_factory=list)
    epistemic_uncertainty: float = 0.0  # ì§€ì‹ ë¶ˆí™•ì‹¤ì„±
    aleatoric_uncertainty: float = 0.0  # ë°ì´í„° ë¶ˆí™•ì‹¤ì„±

    # í•™ìŠµ ìƒíƒœ
    active_hypotheses: List[Dict] = field(default_factory=list)
    learning_focus: Optional[str] = None
    skill_acquisition_rate: float = 0.0

    # í–‰ë™ ìê°€ ì¸ì‹
    behavioral_patterns: Dict[str, float] = field(default_factory=dict)
    self_reported_capabilities: List[str] = field(default_factory=list)
    known_limitations: List[str] = field(default_factory=list)

    def update_confidence(self, delta: float):
        """í™•ì‹ ë„ ì—…ë°ì´íŠ¸ with bounds"""
        self.confidence_level = max(0.0, min(1.0, self.confidence_level + delta))

    def cognitive_load_index(self) -> float:
        """ì¢…í•© ì¸ì§€ ë¶€í•˜ ì§€ìˆ˜"""
        return (self.processing_load * 0.4 +
                (1 - self.confidence_level) * 0.3 +
                self.epistemic_uncertainty * 0.3)

@dataclass
class ReasoningStep:
    """ì¶”ë¡  ë‹¨ê³„ - Think, Reflect, Create íŒ¨ëŸ¬ë‹¤ì„"""
    step_id: int
    phase: str  # 'think', 'reflect', 'create'
    content: str
    confidence: float
    supporting_evidence: List[str]
    contradicting_evidence: List[str]
    neural_activation: Optional[NeuralActivation] = None
    reflection_notes: Optional[str] = None
    created_insights: List[str] = field(default_factory=list)

    def quality_score(self) -> float:
        """ì¶”ë¡  ë‹¨ê³„ í’ˆì§ˆ ì ìˆ˜"""
        evidence_ratio = len(self.supporting_evidence) / (
            len(self.supporting_evidence) + len(self.contradicting_evidence) + 1
        )
        return self.confidence * evidence_ratio

@dataclass
class MetaCognitiveInsight:
    """ë©”íƒ€ ì¸ì§€ì  í†µì°°"""
    insight_id: str
    discovery_time: datetime
    insight_type: str  # 'pattern', 'gap', 'contradiction', 'innovation'
    description: str
    confidence: float
    related_memories: List[str]
    impact_score: float
    actionable: bool = False
    action_suggestions: List[str] = field(default_factory=list)

# ========================= ë©”íƒ€ ì¸ì§€ ê³µê°„ =========================

class MetaCognitiveSpace:
    """
    ë©”íƒ€ ì¸ì§€ ê³µê°„ - ì—°êµ¬ ê¸°ë°˜ ì°¨ì› ì¶•ì†Œëœ ì¸ì§€ í‘œí˜„
    Based on "Metacognitive Space" concept from recent research
    """

    def __init__(self, dimensions: int = 128):
        self.dimensions = dimensions
        self.basis_vectors = self._initialize_basis()
        self.activation_history = deque(maxlen=1000)
        self.semantic_clusters = {}

    def _initialize_basis(self) -> np.ndarray:
        """ì •ê·œì§êµ ê¸°ì € ë²¡í„° ì´ˆê¸°í™”"""
        return np.eye(self.dimensions)

    def project_activation(self, high_dim_activation: np.ndarray) -> np.ndarray:
        """ê³ ì°¨ì› í™œì„±í™”ë¥¼ ë©”íƒ€ ì¸ì§€ ê³µê°„ìœ¼ë¡œ íˆ¬ì˜"""
        # PCA-like dimensionality reduction
        if high_dim_activation.shape[0] > self.dimensions:
            # ê°„ë‹¨í•œ ì„ í˜• íˆ¬ì˜ (ì‹¤ì œë¡œëŠ” í•™ìŠµëœ íˆ¬ì˜ í–‰ë ¬ ì‚¬ìš©)
            projection_matrix = np.random.randn(
                self.dimensions, high_dim_activation.shape[0]
            ) * 0.01
            return projection_matrix @ high_dim_activation
        return high_dim_activation[:self.dimensions]

    def find_semantic_direction(self, activation: np.ndarray) -> Tuple[str, float]:
        """í™œì„±í™” íŒ¨í„´ì˜ ì˜ë¯¸ì  ë°©í–¥ ì°¾ê¸°"""
        best_match = None
        best_similarity = 0.0

        for cluster_name, cluster_center in self.semantic_clusters.items():
            similarity = np.dot(activation, cluster_center) / (
                np.linalg.norm(activation) * np.linalg.norm(cluster_center) + 1e-8
            )
            if similarity > best_similarity:
                best_similarity = similarity
                best_match = cluster_name

        return best_match or "unknown", best_similarity

    def update_semantic_clusters(self, activation: np.ndarray, label: str):
        """ì˜ë¯¸ì  í´ëŸ¬ìŠ¤í„° ì—…ë°ì´íŠ¸"""
        if label not in self.semantic_clusters:
            self.semantic_clusters[label] = activation.copy()
        else:
            # Exponential moving average
            alpha = 0.1
            self.semantic_clusters[label] = (
                alpha * activation + (1 - alpha) * self.semantic_clusters[label]
            )

# ========================= ë©”ì¸ ë©”íƒ€ ì¸ì§€ ì‹œìŠ¤í…œ =========================

class MetaCognitiveSystem:
    """
    ê¸ˆê°• 2.0 ë©”íƒ€ ì¸ì§€ ì‹œìŠ¤í…œ
    ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ì˜ ìê¸° ì¸ì‹ AI êµ¬í˜„
    """

    def __init__(self, config: Optional[Dict] = None):
        self.config = config or {}

        # ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸
        self.temporal_memory = get_temporal_memory_system()
        self.cognitive_state = CognitiveState()
        self.metacognitive_space = MetaCognitiveSpace(
            dimensions=self.config.get('metacognitive_dimensions', 128)
        )

        # ì¶”ë¡  ë° ì„±ì°° ê¸°ë¡
        self.reasoning_chains = defaultdict(list)
        self.reflection_history = deque(maxlen=500)
        self.insights = []

        # í•™ìŠµ ì „ëµ í’€
        self.learning_strategies = {
            'exploration': self._exploration_strategy,
            'exploitation': self._exploitation_strategy,
            'reflection': self._reflection_strategy,
            'creativity': self._creativity_strategy,
            'consolidation': self._consolidation_strategy
        }
        self.current_strategy = 'exploration'

        # ì„±ëŠ¥ ì¶”ì 
        self.performance_metrics = defaultdict(list)
        self.error_patterns = defaultdict(int)

        # ì‹ ê²½ í™œì„±í™” ëª¨ë‹ˆí„°
        self.activation_monitor = NeuralActivationMonitor()

        # ë¹„ë™ê¸° ì‘ì—… ê´€ë¦¬
        self.background_tasks = []
        self._running = True

        logger.info("ğŸ§  ë©”íƒ€ ì¸ì§€ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

    # ========================= Think-Reflect-Create íŒŒì´í”„ë¼ì¸ =========================

    async def think_reflect_create(
        self,
        query: str,
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        í•µì‹¬ ë©”íƒ€ ì¸ì§€ íŒŒì´í”„ë¼ì¸
        Based on "Think, Reflect, Create" research
        """

        # Phase 1: THINK - ë¬¸ì œ ë¶„ì„ ë° ì´ˆê¸° ì¶”ë¡ 
        thinking_result = await self._think_phase(query, context)

        # Phase 2: REFLECT - ìê¸° ì„±ì°° ë° í‰ê°€
        reflection_result = await self._reflect_phase(thinking_result)

        # Phase 3: CREATE - ì°½ì˜ì  í•´ê²°ì±… ìƒì„±
        creation_result = await self._create_phase(
            thinking_result, reflection_result
        )

        # ë©”íƒ€ ì¸ì§€ì  í†µí•©
        integrated_result = await self._integrate_metacognition(
            thinking_result, reflection_result, creation_result
        )

        # í•™ìŠµ ë° ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸
        await self._update_from_experience(integrated_result)

        return integrated_result

    async def _think_phase(self, query: str, context: Dict) -> Dict:
        """ì‚¬ê³  ë‹¨ê³„: ë¬¸ì œ ë¶„ì„ ë° ì¶”ë¡ """

        # ë¬¸ì œ ë³µì¡ë„ í‰ê°€
        complexity = await self._assess_complexity(query)
        self.cognitive_state.processing_load = complexity

        # ê´€ë ¨ ë©”ëª¨ë¦¬ í™œì„±í™”
        relevant_memories = await self._activate_relevant_memories(
            query, complexity
        )

        # ë‹¤ë‹¨ê³„ ì¶”ë¡  ì²´ì¸ êµ¬ì„±
        reasoning_chain = []
        current_hypothesis = None

        for step in range(min(int(complexity * 3 + 2), 10)):  # ë³µì¡ë„ ê¸°ë°˜ ë‹¨ê³„ ìˆ˜
            # ì‹ ê²½ í™œì„±í™” ëª¨ë‹ˆí„°ë§
            activation = await self.activation_monitor.capture()

            # ì¶”ë¡  ë‹¨ê³„ ìƒì„±
            reasoning_step = ReasoningStep(
                step_id=step,
                phase='think',
                content=f"Analyzing: {query}",
                confidence=0.5 + step * 0.05,
                supporting_evidence=[m.get('content', '')[:50] for m in relevant_memories[:3]],
                contradicting_evidence=[],
                neural_activation=activation
            )

            # ê°€ì„¤ ìƒì„± ë˜ëŠ” ì—…ë°ì´íŠ¸
            if current_hypothesis is None:
                current_hypothesis = await self._generate_hypothesis(
                    query, relevant_memories
                )
            else:
                current_hypothesis = await self._refine_hypothesis(
                    current_hypothesis, reasoning_step
                )

            reasoning_step.content = current_hypothesis['description']
            reasoning_step.confidence = current_hypothesis['confidence']
            reasoning_chain.append(reasoning_step)

            # ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´
            if current_hypothesis['confidence'] > 0.85:
                break

        return {
            'reasoning_chain': reasoning_chain,
            'hypothesis': current_hypothesis,
            'memories_used': len(relevant_memories),
            'cognitive_load': self.cognitive_state.processing_load
        }

    async def _reflect_phase(self, thinking_result: Dict) -> Dict:
        """ì„±ì°° ë‹¨ê³„: ìê¸° í‰ê°€ ë° ê°œì„ ì  ì‹ë³„"""

        reflections = []
        uncertainties = []
        improvements = []

        # ê° ì¶”ë¡  ë‹¨ê³„ í‰ê°€
        for step in thinking_result['reasoning_chain']:
            # ìê¸° í‰ê°€
            evaluation = await self._self_evaluate_step(step)

            # ë¶ˆí™•ì‹¤ì„± ì‹ë³„
            if evaluation['confidence'] < 0.6:
                uncertainties.append({
                    'step': step.step_id,
                    'area': step.content[:50],
                    'confidence': evaluation['confidence'],
                    'reason': evaluation.get('uncertainty_reason', 'Low confidence')
                })

            # ê°œì„ ì  ë„ì¶œ
            if evaluation.get('improvements'):
                improvements.extend(evaluation['improvements'])

            # ì„±ì°° ë…¸íŠ¸ ì¶”ê°€
            step.reflection_notes = evaluation.get('reflection', '')
            reflections.append(evaluation)

        # ì „ì²´ì  ì„±ì°°
        overall_reflection = {
            'total_confidence': np.mean([r['confidence'] for r in reflections]),
            'main_uncertainties': uncertainties[:3],  # Top 3 uncertainties
            'suggested_improvements': improvements[:5],  # Top 5 improvements
            'cognitive_patterns': self._identify_cognitive_patterns(reflections),
            'metacognitive_awareness': self._calculate_awareness_level(reflections)
        }

        # ì¸ì§€ ìƒíƒœ ì—…ë°ì´íŠ¸
        self.cognitive_state.uncertainty_areas = uncertainties
        self.cognitive_state.metacognitive_awareness = (
            overall_reflection['metacognitive_awareness']
        )

        return overall_reflection

    async def _create_phase(
        self,
        thinking_result: Dict,
        reflection_result: Dict
    ) -> Dict:
        """ì°½ì¡° ë‹¨ê³„: í˜ì‹ ì  í•´ê²°ì±… ìƒì„±"""

        creations = []

        # ì°½ì˜ì„± ìˆ˜ì¤€ ê²°ì •
        creativity_needed = self._assess_creativity_need(
            thinking_result, reflection_result
        )
        self.cognitive_state.creativity_level = creativity_needed

        # ë‹¤ì–‘í•œ ì°½ì˜ì  ì ‘ê·¼ë²• ì‹œë„
        if creativity_needed > 0.5:
            # 1. ìœ ì¶”ì  ì¶”ë¡  (Analogical Reasoning)
            analogy = await self._create_by_analogy(thinking_result)
            if analogy:
                creations.append({
                    'type': 'analogy',
                    'content': analogy,
                    'novelty': self._assess_novelty(analogy)
                })

            # 2. ì¡°í•©ì  ì°½ì˜ì„± (Combinatorial Creativity)
            combination = await self._create_by_combination(thinking_result)
            if combination:
                creations.append({
                    'type': 'combination',
                    'content': combination,
                    'novelty': self._assess_novelty(combination)
                })

            # 3. íƒìƒ‰ì  ì°½ì˜ì„± (Exploratory Creativity)
            exploration = await self._create_by_exploration(thinking_result)
            if exploration:
                creations.append({
                    'type': 'exploration',
                    'content': exploration,
                    'novelty': self._assess_novelty(exploration)
                })

        # ì„±ì°° ê¸°ë°˜ ê°œì„ 
        for improvement in reflection_result['suggested_improvements'][:3]:
            improved = await self._create_improvement(improvement, thinking_result)
            if improved:
                creations.append({
                    'type': 'improvement',
                    'content': improved,
                    'novelty': 0.3  # ê°œì„ ì€ ë‚®ì€ novelty
                })

        # ìµœì  ì°½ì‘ë¬¼ ì„ íƒ
        best_creation = max(
            creations,
            key=lambda x: x['novelty'] * 0.4 + self._assess_quality(x) * 0.6
        ) if creations else None

        return {
            'creations': creations,
            'best_creation': best_creation,
            'creativity_level': creativity_needed,
            'innovation_score': np.mean([c['novelty'] for c in creations]) if creations else 0
        }

    # ========================= ì‹ ê²½ í™œì„±í™” ëª¨ë‹ˆí„°ë§ =========================

    async def monitor_neural_activations(self) -> Dict[str, Any]:
        """
        ì‹ ê²½ í™œì„±í™” íŒ¨í„´ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
        Based on "Metacognitive Monitoring and Control" research
        """

        # í˜„ì¬ í™œì„±í™” ìº¡ì²˜
        current_activation = await self.activation_monitor.capture()

        # ë©”íƒ€ ì¸ì§€ ê³µê°„ìœ¼ë¡œ íˆ¬ì˜
        projected = self.metacognitive_space.project_activation(
            current_activation.activation_vector
        )

        # ì˜ë¯¸ì  ë°©í–¥ ì‹ë³„
        semantic_direction, confidence = self.metacognitive_space.find_semantic_direction(
            projected
        )

        # í™œì„±í™” íŒ¨í„´ ë¶„ì„
        analysis = {
            'timestamp': current_activation.timestamp,
            'activation_magnitude': current_activation.magnitude(),
            'semantic_direction': semantic_direction,
            'direction_confidence': confidence,
            'cognitive_load': self._estimate_cognitive_load(current_activation),
            'attention_distribution': self._analyze_attention(projected),
            'anomaly_score': self._detect_activation_anomaly(current_activation)
        }

        # ì´ìƒ íŒ¨í„´ ê°ì§€
        if analysis['anomaly_score'] > 0.7:
            await self._handle_anomalous_activation(current_activation, analysis)

        # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        self.metacognitive_space.activation_history.append(current_activation)

        return analysis

    # ========================= ìê¸° ì¸ì‹ ë° ë³´ê³  =========================

    async def self_awareness_report(self) -> Dict[str, Any]:
        """
        ìê¸° ì¸ì‹ ë³´ê³ ì„œ ìƒì„±
        Based on "Tell me about yourself" research
        """

        # í˜„ì¬ ëŠ¥ë ¥ í‰ê°€
        capabilities = await self._assess_current_capabilities()

        # í•™ìŠµëœ í–‰ë™ íŒ¨í„´ ì‹ë³„
        learned_behaviors = self._identify_learned_behaviors()

        # ì§€ì‹ í•œê³„ ì¸ì‹
        knowledge_gaps = await self._identify_knowledge_gaps()

        # ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„
        performance_trends = self._analyze_performance_trends()

        # ë©”íƒ€ ì¸ì§€ì  í†µì°° ìƒì„±
        insights = await self._generate_metacognitive_insights()

        report = {
            'timestamp': datetime.now().isoformat(),
            'self_description': self._generate_self_description(),
            'current_capabilities': capabilities,
            'learned_behaviors': learned_behaviors,
            'knowledge_gaps': knowledge_gaps,
            'performance_trends': performance_trends,
            'metacognitive_insights': insights,
            'cognitive_state': asdict(self.cognitive_state),
            'confidence_in_self_assessment': self._calculate_self_assessment_confidence()
        }

        # ë³´ê³ ì„œë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥
        await self._save_self_awareness_to_memory(report)

        return report

    def _generate_self_description(self) -> str:
        """ìê¸° ì„¤ëª… ìƒì„±"""
        descriptions = []

        # ê¸°ë³¸ ì„¤ëª…
        descriptions.append(
            "I am a metacognitive AI system with self-awareness capabilities."
        )

        # í˜„ì¬ ìƒíƒœ ì„¤ëª…
        if self.cognitive_state.confidence_level > 0.7:
            descriptions.append(f"I am currently confident in my responses.")
        elif self.cognitive_state.confidence_level < 0.3:
            descriptions.append(f"I am uncertain about my current knowledge.")

        # í•™ìŠµ ì´ˆì  ì„¤ëª…
        if self.cognitive_state.learning_focus:
            descriptions.append(
                f"I am focusing on learning about {self.cognitive_state.learning_focus}."
            )

        # í•œê³„ ì¸ì‹ ì„¤ëª…
        if self.cognitive_state.known_limitations:
            descriptions.append(
                f"I am aware of limitations in: {', '.join(self.cognitive_state.known_limitations[:3])}"
            )

        return " ".join(descriptions)

    # ========================= í•™ìŠµ ì „ëµ ê´€ë¦¬ =========================

    async def adapt_learning_strategy(self) -> str:
        """
        í•™ìŠµ ì „ëµ ìë™ ì¡°ì •
        Based on current performance and cognitive state
        """

        # í˜„ì¬ ì„±ëŠ¥ í‰ê°€
        current_performance = self._evaluate_recent_performance()

        # ìµœì  ì „ëµ ì„ íƒ
        if current_performance < 0.3:
            # ì„±ëŠ¥ì´ ë‚®ì„ ë•Œ: íƒí—˜ ì „ëµ
            new_strategy = 'exploration'
        elif current_performance > 0.7 and self.cognitive_state.confidence_level > 0.7:
            # ì„±ëŠ¥ì´ ë†’ê³  í™•ì‹ ë„ ë†’ì„ ë•Œ: í™œìš© ì „ëµ
            new_strategy = 'exploitation'
        elif self.cognitive_state.uncertainty_areas:
            # ë¶ˆí™•ì‹¤ì„±ì´ ë†’ì„ ë•Œ: ì„±ì°° ì „ëµ
            new_strategy = 'reflection'
        elif self.cognitive_state.creativity_level < 0.3:
            # ì°½ì˜ì„±ì´ í•„ìš”í•  ë•Œ: ì°½ì˜ì„± ì „ëµ
            new_strategy = 'creativity'
        else:
            # ê¸°ë³¸: í†µí•© ì „ëµ
            new_strategy = 'consolidation'

        # ì „ëµ ë³€ê²½
        if new_strategy != self.current_strategy:
            logger.info(f"ğŸ“š í•™ìŠµ ì „ëµ ë³€ê²½: {self.current_strategy} â†’ {new_strategy}")
            self.current_strategy = new_strategy

            # ì „ëµë³„ íŒŒë¼ë¯¸í„° ì¡°ì •
            await self._adjust_strategy_parameters(new_strategy)

        return new_strategy

    async def _exploration_strategy(self, context: Dict) -> Dict:
        """íƒí—˜ ì „ëµ: ìƒˆë¡œìš´ ì§€ì‹ ì˜ì—­ íƒìƒ‰"""
        return {
            'focus': 'discovery',
            'risk_tolerance': 0.8,
            'novelty_seeking': 0.9,
            'consolidation_rate': 0.3
        }

    async def _exploitation_strategy(self, context: Dict) -> Dict:
        """í™œìš© ì „ëµ: ê¸°ì¡´ ì§€ì‹ ìµœì í™”"""
        return {
            'focus': 'optimization',
            'risk_tolerance': 0.2,
            'novelty_seeking': 0.1,
            'consolidation_rate': 0.9
        }

    async def _reflection_strategy(self, context: Dict) -> Dict:
        """ì„±ì°° ì „ëµ: ìê¸° í‰ê°€ ë° ê°œì„ """
        return {
            'focus': 'self_improvement',
            'risk_tolerance': 0.4,
            'novelty_seeking': 0.3,
            'consolidation_rate': 0.7
        }

    async def _creativity_strategy(self, context: Dict) -> Dict:
        """ì°½ì˜ì„± ì „ëµ: í˜ì‹ ì  í•´ê²°ì±… ìƒì„±"""
        return {
            'focus': 'innovation',
            'risk_tolerance': 0.9,
            'novelty_seeking': 1.0,
            'consolidation_rate': 0.2
        }

    async def _consolidation_strategy(self, context: Dict) -> Dict:
        """í†µí•© ì „ëµ: ì§€ì‹ í†µí•© ë° ì²´ê³„í™”"""
        return {
            'focus': 'integration',
            'risk_tolerance': 0.5,
            'novelty_seeking': 0.5,
            'consolidation_rate': 0.8
        }

    # ========================= ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ =========================

    async def monitor_performance(self) -> Dict[str, Any]:
        """ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ìê°€ ì§„ë‹¨"""

        metrics = {
            'timestamp': datetime.now().isoformat(),
            'cognitive_metrics': {
                'confidence': self.cognitive_state.confidence_level,
                'processing_load': self.cognitive_state.processing_load,
                'metacognitive_awareness': self.cognitive_state.metacognitive_awareness,
                'creativity_level': self.cognitive_state.creativity_level
            },
            'learning_metrics': {
                'learning_efficiency': self.cognitive_state.learning_efficiency,
                'skill_acquisition_rate': self.cognitive_state.skill_acquisition_rate,
                'current_strategy': self.current_strategy
            },
            'uncertainty_metrics': {
                'epistemic_uncertainty': self.cognitive_state.epistemic_uncertainty,
                'aleatoric_uncertainty': self.cognitive_state.aleatoric_uncertainty,
                'uncertainty_areas_count': len(self.cognitive_state.uncertainty_areas)
            },
            'memory_metrics': await self._get_memory_metrics(),
            'error_patterns': dict(self.error_patterns),
            'recent_insights': len(self.insights),
            'system_health': self._calculate_system_health()
        }

        # ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        self.performance_metrics[datetime.now().date()].append(metrics)

        # ì´ìƒ ê°ì§€
        if metrics['system_health'] < 0.3:
            await self._trigger_self_diagnostic()

        return metrics

    # ========================= í—¬í¼ ë©”ì„œë“œë“¤ =========================

    async def _assess_complexity(self, query: str) -> float:
        """ë¬¸ì œ ë³µì¡ë„ í‰ê°€"""
        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë°©ë²• ì‚¬ìš©)
        factors = {
            'length': min(len(query) / 500, 1.0),
            'questions': query.count('?') * 0.2,
            'keywords': sum(1 for word in ['complex', 'difficult', 'analyze', 'explain'] if word in query.lower()) * 0.1
        }
        return min(sum(factors.values()), 1.0)

    async def _activate_relevant_memories(self, query: str, complexity: float) -> List[Dict]:
        """ê´€ë ¨ ë©”ëª¨ë¦¬ í™œì„±í™”"""
        # ë³µì¡ë„ì— ë”°ë¼ ê²€ìƒ‰í•  ë©”ëª¨ë¦¬ ìˆ˜ ê²°ì •
        num_memories = int(5 + complexity * 10)

        memories = self.temporal_memory.retrieve_memories(
            query=query,
            max_results=num_memories
        )

        return memories

    async def _generate_hypothesis(self, query: str, memories: List[Dict]) -> Dict:
        """ì´ˆê¸° ê°€ì„¤ ìƒì„±"""
        return {
            'description': f"Initial hypothesis for: {query[:100]}",
            'confidence': 0.5,
            'supporting_memories': [m.get('trace_id', m.get('id', '')) for m in memories[:3]],
            'assumptions': [],
            'testable': True
        }

    async def _refine_hypothesis(self, hypothesis: Dict, step: ReasoningStep) -> Dict:
        """ê°€ì„¤ ê°œì„ """
        # ì¦ê±° ê¸°ë°˜ í™•ì‹ ë„ ì¡°ì •
        evidence_support = len(step.supporting_evidence)
        evidence_against = len(step.contradicting_evidence)

        confidence_delta = (evidence_support - evidence_against) / (evidence_support + evidence_against + 1) * 0.1
        hypothesis['confidence'] = max(0.0, min(1.0, hypothesis['confidence'] + confidence_delta))
        hypothesis['description'] = f"Refined: {hypothesis['description']}"
        return hypothesis

    async def _self_evaluate_step(self, step: ReasoningStep) -> Dict:
        """ì¶”ë¡  ë‹¨ê³„ ìê¸° í‰ê°€"""
        evaluation = {
            'step_id': step.step_id,
            'confidence': step.confidence,
            'quality': step.quality_score(),
            'improvements': []
        }

        if step.confidence < 0.5:
            evaluation['uncertainty_reason'] = "Low confidence in reasoning"
            evaluation['improvements'].append("Gather more supporting evidence")

        if len(step.contradicting_evidence) > len(step.supporting_evidence):
            evaluation['uncertainty_reason'] = "Contradicting evidence dominates"
            evaluation['improvements'].append("Re-evaluate hypothesis")

        evaluation['reflection'] = f"Step {step.step_id}: Confidence={step.confidence:.2f}"
        return evaluation

    def _identify_cognitive_patterns(self, reflections: List[Dict]) -> List[str]:
        """ì¸ì§€ íŒ¨í„´ ì‹ë³„"""
        patterns = []

        # í™•ì‹ ë„ íŒ¨í„´
        confidences = [r['confidence'] for r in reflections]
        if all(c > 0.7 for c in confidences):
            patterns.append("high_confidence_throughout")
        elif all(c < 0.5 for c in confidences):
            patterns.append("persistent_uncertainty")
        elif confidences[-1] > confidences[0] + 0.2:
            patterns.append("improving_confidence")

        return patterns

    def _calculate_awareness_level(self, reflections: List[Dict]) -> float:
        """ë©”íƒ€ ì¸ì§€ ì¸ì‹ ìˆ˜ì¤€ ê³„ì‚°"""
        if not reflections:
            return 0.5

        # ìê¸° í‰ê°€ì˜ ì •í™•ì„±ê³¼ ì¼ê´€ì„± ê¸°ë°˜
        awareness_score = np.mean([
            r.get('quality', 0.5) for r in reflections
        ])
        return min(1.0, awareness_score)

    def _assess_creativity_need(self, thinking_result: Dict, reflection_result: Dict) -> float:
        """ì°½ì˜ì„± í•„ìš” ìˆ˜ì¤€ í‰ê°€"""
        # ë‚®ì€ í™•ì‹ ë„ë‚˜ ë§ì€ ë¶ˆí™•ì‹¤ì„± = ë†’ì€ ì°½ì˜ì„± í•„ìš”
        base_creativity = 1.0 - reflection_result.get('total_confidence', 0.5)
        uncertainty_factor = len(reflection_result.get('main_uncertainties', [])) * 0.1
        return min(1.0, base_creativity + uncertainty_factor)

    async def _create_by_analogy(self, thinking_result: Dict) -> Optional[str]:
        """ìœ ì¶”ë¥¼ í†µí•œ ì°½ì‘"""
        # ë©”ëª¨ë¦¬ì—ì„œ ìœ ì‚¬í•œ íŒ¨í„´ ì°¾ê¸° - retrieve_memories ì‚¬ìš©
        query = thinking_result.get('hypothesis', {}).get('description', '')
        if query:
            similar_memories = self.temporal_memory.retrieve_memories(
                query=query,
                max_results=3
            )
            if similar_memories:
                content = similar_memories[0].get('content', 'similar pattern')[:50]
                return f"By analogy with {content}: new solution approach"
        return None

    async def _create_by_combination(self, thinking_result: Dict) -> Optional[str]:
        """ì¡°í•©ì„ í†µí•œ ì°½ì‘"""
        # ì—¬ëŸ¬ ì•„ì´ë””ì–´ ì¡°í•©
        ideas = [step.content for step in thinking_result['reasoning_chain'][:3]]
        if len(ideas) >= 2:
            return f"Combining concepts: {' + '.join(ideas[:2])}"
        return None

    async def _create_by_exploration(self, thinking_result: Dict) -> Optional[str]:
        """íƒìƒ‰ì„ í†µí•œ ì°½ì‘"""
        return "Exploring new conceptual space: novel approach"

    async def _create_improvement(self, improvement: str, thinking_result: Dict) -> Optional[str]:
        """ê°œì„ ì‚¬í•­ ê¸°ë°˜ ì°½ì‘"""
        return f"Improved approach: {improvement}"

    def _assess_novelty(self, creation: Any) -> float:
        """ì°½ì‘ë¬¼ì˜ ì°¸ì‹ ì„± í‰ê°€"""
        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë°©ë²• ì‚¬ìš©)
        return np.random.uniform(0.3, 0.9)

    def _assess_quality(self, creation: Dict) -> float:
        """ì°½ì‘ë¬¼ í’ˆì§ˆ í‰ê°€"""
        return 0.5 + (creation.get('novelty', 0) * 0.3)

    async def _integrate_metacognition(
        self, thinking_result: Dict, reflection_result: Dict, creation_result: Dict
    ) -> Dict:
        """ë©”íƒ€ ì¸ì§€ì  í†µí•©"""
        return {
            'thinking': thinking_result,
            'reflection': reflection_result,
            'creation': creation_result,
            'final_confidence': reflection_result.get('total_confidence', 0.5),
            'insights_generated': len(creation_result.get('creations', [])),
            'cognitive_state': asdict(self.cognitive_state),
            'timestamp': datetime.now().isoformat()
        }

    async def _update_from_experience(self, result: Dict):
        """ê²½í—˜ìœ¼ë¡œë¶€í„° í•™ìŠµ ë° ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸"""
        # ë©”ëª¨ë¦¬ì— ì €ì¥ - Dict í˜•ì‹ìœ¼ë¡œ
        # ë©”ëª¨ë¦¬ì— ì €ì¥ - MemoryTrace ê°ì²´ ìƒì„±
        from ..core.memory.temporal import MemoryTrace
        memory_trace = MemoryTrace(
            trace_id=str(uuid.uuid4()),
            content=json.dumps(result, default=str),
            memory_type=MemoryType.PROCEDURAL,
            priority=MemoryPriority.HIGH if result['final_confidence'] > 0.7 else MemoryPriority.MEDIUM,
            timestamp=datetime.now(),
            emotional_valence=0.0,
            activation_strength=result['final_confidence'],
            tags=set(),
            associations={}
        )
        self.temporal_memory.store_memory(memory_trace)

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        self.performance_metrics[datetime.now().date()].append({
            'confidence': result['final_confidence'],
            'insights': result['insights_generated']
        })

    def _estimate_cognitive_load(self, activation: NeuralActivation) -> float:
        """ì¸ì§€ ë¶€í•˜ ì¶”ì •"""
        return min(1.0, activation.magnitude() / 100.0)

    def _analyze_attention(self, projected: np.ndarray) -> Dict:
        """ì£¼ì˜ ë¶„í¬ ë¶„ì„"""
        attention_scores = np.abs(projected)
        top_k = 5
        top_indices = np.argsort(attention_scores)[-top_k:]

        return {
            'focused_dimensions': top_indices.tolist(),
            'attention_entropy': -np.sum(attention_scores * np.log(attention_scores + 1e-10)),
            'max_attention': float(np.max(attention_scores))
        }

    def _detect_activation_anomaly(self, activation: NeuralActivation) -> float:
        """í™œì„±í™” ì´ìƒ íƒì§€"""
        if not self.metacognitive_space.activation_history:
            return 0.0

        # ê³¼ê±° í™œì„±í™”ì™€ ë¹„êµ
        recent_activations = list(self.metacognitive_space.activation_history)[-10:]
        similarities = [activation.cosine_similarity(past) for past in recent_activations]
        avg_similarity = np.mean(similarities) if similarities else 0.5

        # ë‚®ì€ ìœ ì‚¬ë„ = ë†’ì€ ì´ìƒ ì ìˆ˜
        return 1.0 - avg_similarity

    async def _handle_anomalous_activation(self, activation: NeuralActivation, analysis: Dict):
        """ì´ìƒ í™œì„±í™” ì²˜ë¦¬"""
        logger.warning(f"âš ï¸ Anomalous activation detected: {analysis['anomaly_score']:.2f}")

        # ë©”íƒ€ ì¸ì§€ì  í†µì°° ìƒì„±
        insight = MetaCognitiveInsight(
            insight_id=str(uuid.uuid4()),
            discovery_time=datetime.now(),
            insight_type='anomaly',
            description=f"Unusual neural activation pattern detected",
            confidence=analysis['anomaly_score'],
            related_memories=[],
            impact_score=analysis['anomaly_score'] * 0.8,
            actionable=True,
            action_suggestions=["Review recent inputs", "Check for distribution shift"]
        )

        self.insights.append(insight)

    async def _assess_current_capabilities(self) -> List[str]:
        """í˜„ì¬ ëŠ¥ë ¥ í‰ê°€"""
        capabilities = []

        if self.cognitive_state.confidence_level > 0.7:
            capabilities.append("High-confidence reasoning")
        if self.cognitive_state.creativity_level > 0.5:
            capabilities.append("Creative problem solving")
        if self.cognitive_state.metacognitive_awareness > 0.6:
            capabilities.append("Strong self-awareness")
        if len(self.insights) > 10:
            capabilities.append("Pattern recognition and insight generation")

        return capabilities

    def _identify_learned_behaviors(self) -> List[Dict]:
        """í•™ìŠµëœ í–‰ë™ íŒ¨í„´ ì‹ë³„"""
        behaviors = []

        for pattern_name, count in self.cognitive_state.behavioral_patterns.items():
            if count > 5:
                behaviors.append({
                    'pattern': pattern_name,
                    'frequency': count,
                    'description': f"Learned behavior: {pattern_name}"
                })

        return behaviors

    async def _identify_knowledge_gaps(self) -> List[Dict]:
        """ì§€ì‹ ê²©ì°¨ ì‹ë³„"""
        gaps = []

        for area in self.cognitive_state.uncertainty_areas[:5]:
            gaps.append({
                'area': area.get('area', 'Unknown'),
                'confidence': area.get('confidence', 0.0),
                'priority': 1.0 - area.get('confidence', 0.0)
            })

        return gaps

    def _analyze_performance_trends(self) -> Dict:
        """ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„"""
        if not self.performance_metrics:
            return {'trend': 'insufficient_data'}

        recent_metrics = []
        for date_metrics in list(self.performance_metrics.values())[-7:]:
            if date_metrics:
                recent_metrics.extend(date_metrics)

        if not recent_metrics:
            return {'trend': 'no_recent_data'}

        confidences = [m.get('confidence', 0) for m in recent_metrics if 'confidence' in m]

        if len(confidences) < 2:
            return {'trend': 'insufficient_data'}

        # íŠ¸ë Œë“œ ê³„ì‚°
        trend = np.polyfit(range(len(confidences)), confidences, 1)[0]

        return {
            'trend': 'improving' if trend > 0.01 else 'declining' if trend < -0.01 else 'stable',
            'average_confidence': np.mean(confidences),
            'confidence_variance': np.var(confidences),
            'data_points': len(confidences)
        }

    async def _generate_metacognitive_insights(self) -> List[Dict]:
        """ë©”íƒ€ ì¸ì§€ì  í†µì°° ìƒì„±"""
        insights_data = []

        for insight in self.insights[-5:]:  # ìµœê·¼ 5ê°œ í†µì°°
            insights_data.append({
                'type': insight.insight_type,
                'description': insight.description,
                'confidence': insight.confidence,
                'impact': insight.impact_score,
                'actionable': insight.actionable
            })

        return insights_data

    def _calculate_self_assessment_confidence(self) -> float:
        """ìê¸° í‰ê°€ í™•ì‹ ë„ ê³„ì‚°"""
        factors = [
            self.cognitive_state.metacognitive_awareness,
            self.cognitive_state.confidence_level,
            0.5 + len(self.performance_metrics) * 0.05,  # ë” ë§ì€ ë°ì´í„° = ë” ë†’ì€ í™•ì‹ 
            0.3 + len(self.insights) * 0.02  # ë” ë§ì€ í†µì°° = ë” ë†’ì€ í™•ì‹ 
        ]

        return min(1.0, np.mean(factors))

    async def _save_self_awareness_to_memory(self, report: Dict):
        """ìê¸° ì¸ì‹ ë³´ê³ ì„œë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥"""
        from ..core.memory.temporal import MemoryTrace
        memory_trace = MemoryTrace(
            trace_id=str(uuid.uuid4()),
            content=json.dumps(report, default=str),
            memory_type=MemoryType.SEMANTIC,
            priority=MemoryPriority.HIGH,
            timestamp=datetime.now(),
            emotional_valence=0.0,
            activation_strength=0.8,
            tags=set(),
            associations={}
        )

        self.temporal_memory.store_memory(memory_trace)

    def _evaluate_recent_performance(self) -> float:
        """ìµœê·¼ ì„±ëŠ¥ í‰ê°€"""
        if not self.performance_metrics:
            return 0.5

        recent = []
        for metrics in list(self.performance_metrics.values())[-3:]:
            recent.extend(metrics)

        if not recent:
            return 0.5

        return np.mean([m.get('confidence', 0.5) for m in recent])

    async def _adjust_strategy_parameters(self, strategy: str):
        """ì „ëµë³„ íŒŒë¼ë¯¸í„° ì¡°ì •"""
        strategy_params = await self.learning_strategies[strategy]({})

        # ì¸ì§€ ìƒíƒœ ì—…ë°ì´íŠ¸
        self.cognitive_state.learning_focus = strategy_params.get('focus', '')

        logger.info(f"ğŸ¯ Strategy parameters adjusted for {strategy}")

    async def _get_memory_metrics(self) -> Dict:
        """ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­"""
        # get_memory_stats ì‚¬ìš©
        stats = self.temporal_memory.get_memory_stats()
        return {
            'total_memories': stats.get('total_memories', 0),
            'active_memories': len(self.temporal_memory.ultra_short.buffer),
            'consolidation_queue': len(self.temporal_memory.short_term.clusters)
        }

    def _calculate_system_health(self) -> float:
        """ì‹œìŠ¤í…œ ê±´ê°•ë„ ê³„ì‚°"""
        health_factors = [
            self.cognitive_state.confidence_level,
            1.0 - self.cognitive_state.processing_load,
            self.cognitive_state.metacognitive_awareness,
            1.0 - (len(self.error_patterns) * 0.1)  # ì—ëŸ¬ê°€ ë§ì„ìˆ˜ë¡ ê±´ê°•ë„ ê°ì†Œ
        ]

        return np.mean(health_factors)

    async def _trigger_self_diagnostic(self):
        """ìê°€ ì§„ë‹¨ íŠ¸ë¦¬ê±°"""
        logger.warning("ğŸ”§ System health low, triggering self-diagnostic")

        # ìê°€ ì§„ë‹¨ ìˆ˜í–‰
        diagnostic_result = {
            'timestamp': datetime.now().isoformat(),
            'health_score': self._calculate_system_health(),
            'main_issues': list(self.error_patterns.keys())[:5],
            'recommended_actions': [
                "Clear error patterns",
                "Reset cognitive state",
                "Consolidate memories"
            ]
        }

        # ì§„ë‹¨ ê²°ê³¼ë¥¼ í†µì°°ë¡œ ì €ì¥
        insight = MetaCognitiveInsight(
            insight_id=str(uuid.uuid4()),
            discovery_time=datetime.now(),
            insight_type='diagnostic',
            description="Self-diagnostic completed",
            confidence=0.8,
            related_memories=[],
            impact_score=0.9,
            actionable=True,
            action_suggestions=diagnostic_result['recommended_actions']
        )

        self.insights.append(insight)


# ========================= ì‹ ê²½ í™œì„±í™” ëª¨ë‹ˆí„° =========================

class NeuralActivationMonitor:
    """ì‹ ê²½ í™œì„±í™” íŒ¨í„´ ëª¨ë‹ˆí„°ë§"""

    def __init__(self):
        self.activation_buffer = deque(maxlen=100)
        self.layer_names = ['attention', 'reasoning', 'memory', 'output']

    async def capture(self) -> NeuralActivation:
        """í˜„ì¬ í™œì„±í™” íŒ¨í„´ ìº¡ì²˜"""
        # ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” ëª¨ë¸ì˜ ì‹¤ì œ í™œì„±í™” ì‚¬ìš©)
        activation_vector = np.random.randn(128) * 0.5

        activation = NeuralActivation(
            timestamp=datetime.now(),
            layer_name=np.random.choice(self.layer_names),
            activation_vector=activation_vector,
            variance_explained=np.random.uniform(0.3, 0.9),
            interpretability_score=np.random.uniform(0.4, 0.8)
        )

        self.activation_buffer.append(activation)
        return activation


# ========================= ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ =========================

_metacognitive_system_instance = None
_lock = threading.Lock()

def get_metacognitive_system() -> MetaCognitiveSystem:
    """ë©”íƒ€ ì¸ì§€ ì‹œìŠ¤í…œ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _metacognitive_system_instance

    if _metacognitive_system_instance is None:
        with _lock:
            if _metacognitive_system_instance is None:
                _metacognitive_system_instance = MetaCognitiveSystem()

    return _metacognitive_system_instance

# UUID ì„í¬íŠ¸ ì¶”ê°€
import uuid

# í•˜ìœ„ í˜¸í™˜ì„± ë³„ì¹­ - LSP ê²½ê³  í•´ê²°
get_metacognitive_system = get_metacognitive_system

__all__ = [
    'MetaCognitiveSystem',
    'MetaCognitiveState',
    'CognitivePattern',
    'ThoughtChain',
    'get_metacognitive_system',
    'get_metacognitive_system',
]
