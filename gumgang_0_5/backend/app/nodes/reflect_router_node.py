# âœ… reflect_router_node.py
# ì§ˆë¬¸ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ LangGraph ë‚´ë¶€ reflect íë¦„ì„ ë¶„ê¸°í•¨

from langchain_core.runnables import RunnableLambda
from langchain_core.messages import HumanMessage
from app.nodes.status_report import status_report
from app.nodes.generate_only_node import generate_only_node

# âœ… ì˜ë¯¸ ê¸°ë°˜ í‚¤ì›Œë“œ ì •ì˜
KEYWORDS_TRIGGER_MEMORY = ["ìƒíƒœ", "êµ¬ì¡°", "ê¸°ì–µ", "ë²„ì „", "ìˆ˜ì •", "ë¡œë“œë§µ"]

# âœ… ë¶„ê¸° ë¡œì§ (verbose ì§€ì›)
def route_by_query_verbose(inputs: dict, verbose: bool = False) -> dict:
    query = inputs.get("query", "")
    if verbose:
        print(f"ğŸ” reflect_router_node input query: {query}")

    if any(keyword in query for keyword in KEYWORDS_TRIGGER_MEMORY):
        if verbose:
            print("ğŸ”€ í‚¤ì›Œë“œ ê°ì§€ â†’ status_report")
        return {"next": "status_report"}
    else:
        if verbose:
            print("â¡ï¸ í‚¤ì›Œë“œ ì—†ìŒ â†’ generate_only_node")
        return {"next": "generate_only_node"}

# âœ… LangGraph ë¼ìš°í„° ë…¸ë“œ ì •ì˜
def build_reflect_router_node(verbose: bool = False) -> RunnableLambda:
    return RunnableLambda(lambda inputs: route_by_query_verbose(inputs, verbose=verbose))

# ğŸ“Œ ì—°ê²° ì˜ˆì‹œ (graph.py ë‚´ì—ì„œ ì‚¬ìš©)
# reflect_router_node = build_reflect_router_node(verbose=True)
