import os
import json
from typing import List
from langchain_community.vectorstores import Chroma
from langchain.schema import Document
from langchain_openai import OpenAIEmbeddings
from dotenv import load_dotenv

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.envì— OpenAI API í‚¤ê°€ ìˆì–´ì•¼ í•¨)
load_dotenv()

# âœ… ê¸°ë³¸ ê²½ë¡œ ì •ì˜
SOURCE_PATH = os.path.abspath(
    os.path.join(os.path.dirname(__file__), "../memory/sources/structure/backend_structure_knowledge.json")
)
CHROMA_PATH = os.path.abspath(
    os.path.join(os.path.dirname(__file__), "../memory/gumgang_memory")
)

# âœ… JSON ë¡œë“œ í•¨ìˆ˜
def load_backend_structure() -> List[Document]:
    if not os.path.exists(SOURCE_PATH):
        raise FileNotFoundError(f"âŒ êµ¬ì¡° JSON íŒŒì¼ ì—†ìŒ: {SOURCE_PATH}")

    with open(SOURCE_PATH, "r", encoding="utf-8") as f:
        data = json.load(f)

    docs = []
    # ë°ì´í„°ê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
    if isinstance(data, dict):
        data = [data]

    for entry in data:
        if isinstance(entry, dict):
            content = entry.get("content", "")
            metadata = {
                "source": "backend_structure_knowledge",
                "type": entry.get("type", "backend"),
                "filename": entry.get("filename", ""),
                "path": entry.get("path", ""),
            }
            docs.append(Document(page_content=content, metadata=metadata))
        else:
            print(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ í˜•ì‹: {entry} (ë¬´ì‹œë¨)")
    return docs

# âœ… ì¸ê²ŒìŠ¤íŠ¸ ì‹¤í–‰
def ingest():
    print("ğŸ“¥ ë°±ì—”ë“œ êµ¬ì¡° JSON ë¡œë”© ì¤‘...")
    documents = load_backend_structure()

    print(f"ğŸ“¦ ë¬¸ì„œ ê°œìˆ˜: {len(documents)}")
    print("ğŸ” ì„ë² ë”© ë° ì €ì¥ ê²½ë¡œ:", CHROMA_PATH)

    # âœ… ì„ë² ë”© ë° ì €ì¥
    db = Chroma.from_documents(
        documents=documents,
        embedding=OpenAIEmbeddings(),
        persist_directory=CHROMA_PATH
    )
    db.persist()
    print("âœ… ë°±ì—”ë“œ êµ¬ì¡° ì¸ê²ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    ingest()
