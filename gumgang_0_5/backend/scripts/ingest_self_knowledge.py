import os
import json
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from dotenv import load_dotenv

load_dotenv()

PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../"))
SUMMARY_PATH = os.path.join(PROJECT_ROOT, "backend/data/file_summaries.json")
STRUCTURE_PATH = os.path.join(PROJECT_ROOT, "backend/data/folder_structure.json")
CHROMA_PATH = os.path.join(PROJECT_ROOT, "backend/memory/gumgang_memory")

# í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„¤ì •
text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)

def make_documents_from_json(json_data, prefix=""):
    documents = []
    for key, value in json_data.items():
        content = f"[{prefix}] {key}\n{json.dumps(value, ensure_ascii=False, indent=2)}"
        splits = text_splitter.create_documents([content])
        documents.extend(splits)
    return documents

def main():
    print("ğŸ“¦ ê¸ˆê°• ìê¸° êµ¬ì¡° ê¸°ì–µ ì¸ê²ŒìŠ¤íŠ¸ ì‹œì‘...")

    # JSON ë¡œë“œ
    with open(SUMMARY_PATH, encoding="utf-8") as f:
        summary_data = json.load(f)
    with open(STRUCTURE_PATH, encoding="utf-8") as f:
        folder_data = json.load(f)

    # ë¬¸ì„œ ìƒì„±
    docs_summary = make_documents_from_json(summary_data, "íŒŒì¼ ìš”ì•½")
    docs_folder = make_documents_from_json(folder_data, "í´ë” êµ¬ì¡°")

    all_docs = docs_summary + docs_folder
    print(f"âœ… ë¬¸ì„œ ì´ {len(all_docs)}ê°œ ìƒì„±")

    # ì„ë² ë”© ë° Chroma ì €ì¥
    embedding = OpenAIEmbeddings()
    vectordb = Chroma.from_documents(
        documents=all_docs,
        embedding=embedding,
        persist_directory=CHROMA_PATH
    )

    vectordb.persist()
    print(f"âœ… ì¸ê²ŒìŠ¤íŠ¸ ì™„ë£Œ â†’ {CHROMA_PATH}")

if __name__ == "__main__":
    main()


