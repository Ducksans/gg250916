import os
import json
from langchain_community.vectorstores import Chroma
from langchain.schema import Document
from langchain_openai import OpenAIEmbeddings
from dotenv import load_dotenv

load_dotenv()

BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
REPORT_PATH = os.path.join(BASE_DIR, "data/structure_report.json")
VECTOR_DIR = os.path.join(BASE_DIR, "memory/gumgang_memory")

def load_split_documents():
    with open(REPORT_PATH, "r", encoding="utf-8") as f:
        report = json.load(f)

    docs = []

    if "summary" in report:
        docs.append(Document(
            page_content=f"ğŸ“Š êµ¬ì¡° ìš”ì•½: {report['summary']}",
            metadata={"source": "structure_report", "category": "summary"}
        ))

    def add_section(key, title):
        entries = report.get(key, [])
        if entries:
            if isinstance(entries[0], dict):
                contents = "\n".join([f"{k}: {v}" for item in entries for k, v in item.items()])
            else:
                contents = "\n".join(entries)

            docs.append(Document(
                page_content=f"{title}\n{contents}",
                metadata={"source": "structure_report", "category": key}
            ))

    add_section("missing_files", "âŒ ëˆ„ë½ëœ íŒŒì¼:")
    add_section("duplicate_files", "ğŸ” ì¤‘ë³µëœ íŒŒì¼:")
    add_section("unused_files", "ğŸ—‘ï¸ ë¯¸ì‚¬ìš© íŒŒì¼:")
    add_section("unlinked_files", "ğŸ”— ì—°ê²°ë˜ì§€ ì•Šì€ íŒŒì¼:")
    add_section("backend_frontend_mismatch", "âš ï¸ ë°±ì—”ë“œ/í”„ë¡ íŠ¸ ë¶ˆì¼ì¹˜:")

    return docs

def ingest():
    docs = load_split_documents()
    embeddings = OpenAIEmbeddings()
    db = Chroma.from_documents(
        documents=docs,
        embedding=embeddings,
        persist_directory=VECTOR_DIR
    )
    db.persist()
    print(f"âœ… êµ¬ì¡° ë¦¬í¬íŠ¸ (ë¶„í• ) ì¸ê²ŒìŠ¤íŠ¸ ì™„ë£Œ â†’ {VECTOR_DIR}, ì´ ë¬¸ì„œ ìˆ˜: {len(docs)}")

if __name__ == "__main__":
    ingest()
