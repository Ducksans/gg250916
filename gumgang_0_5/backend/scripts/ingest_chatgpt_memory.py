import os
import json
from pathlib import Path
from dotenv import load_dotenv
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from tqdm import tqdm

# ğŸŒ± í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ğŸ“ ê²½ë¡œ ì„¤ì •
SOURCE_DIR = "backend/memory/sources/chatgpt/"
VECTOR_DIR = "backend/memory/vectors/chatgpt_memory"

# ğŸ”§ ì„ë² ë”© ëª¨ë¸ + í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í• ê¸°
embedding = OpenAIEmbeddings()
splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)

docs = []

print(f"ğŸ“‚ ì¸ê²ŒìŠ¤íŠ¸ ëŒ€ìƒ í´ë”: {SOURCE_DIR}")

# ğŸ“¦ JSON íŒŒì¼ ìˆœíšŒí•˜ë©° messages íŒŒì‹±
for file in tqdm(Path(SOURCE_DIR).glob("*.json"), desc="ğŸ” íŒŒì¼ ìŠ¤ìº” ì¤‘"):
    try:
        with open(file, "r", encoding="utf-8") as f:
            data = json.load(f)

        # âœ… Plan A: OpenAI ëŒ€í™” í˜•ì‹
        full_text = ""
        messages = data.get("messages", [])
        if isinstance(messages, list):
            for msg in messages:
                role = msg.get("role")
                content = msg.get("content", "").strip()
                if role in ["user", "assistant"] and content:
                    full_text += f"{role.upper()}: {content}\n\n"

        # âœ… Plan B: fallback
        if not full_text.strip():
            if isinstance(data.get("text"), str):
                full_text = data["text"].strip()
            elif isinstance(data.get("content"), str):
                full_text = data["content"].strip()

        if not full_text.strip():
            print(f"âš ï¸ ìœ íš¨í•œ í…ìŠ¤íŠ¸ ì—†ìŒ: {file.name}")
            continue

        metadata = {
            "source": str(file),
            "filename": file.name
        }

        for chunk in splitter.split_text(full_text):
            docs.append(Document(page_content=chunk, metadata=metadata))

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {file.name} â†’ {str(e)}")

# âœ… ì¸ê²ŒìŠ¤íŠ¸ ì‹œì‘
print(f"\nğŸ“¥ ìµœì¢… ì²­í¬ ìˆ˜: {len(docs)}")

db = Chroma(persist_directory=VECTOR_DIR, embedding_function=embedding)

# ğŸ” ë°°ì¹˜ ì¶”ê°€
BATCH_SIZE = 100
for i in tqdm(range(0, len(docs), BATCH_SIZE), desc="ğŸ”„ ì¸ê²ŒìŠ¤íŠ¸ ì¤‘"):
    batch = docs[i:i + BATCH_SIZE]
    try:
        db.add_documents(batch)
    except Exception as e:
        print(f"âŒ ë°°ì¹˜ ì˜¤ë¥˜ @ {i}: {e}")

# ğŸ’¾ ì €ì¥
db.persist()
print("âœ… ì¸ê²ŒìŠ¤íŠ¸ ì™„ë£Œ ë° ë²¡í„° DB ì €ì¥ë¨")
