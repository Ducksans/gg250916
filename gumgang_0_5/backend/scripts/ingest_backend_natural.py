# backend/scripts/ingest_backend_natural.py

import os
import json
from langchain.schema import Document
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from dotenv import load_dotenv

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# âœ… ê²½ë¡œ ì„¤ì • (ìƒëŒ€ ê²½ë¡œ ê¸°ì¤€ìœ¼ë¡œ ì •í™•íˆ ì§€ì •)
SOURCE_PATH = os.path.abspath(
    os.path.join(os.path.dirname(__file__), "../data/backend_structure_natural.json")
)
CHROMA_PATH = os.path.abspath(
    os.path.join(os.path.dirname(__file__), "../memory/gumgang_memory")
)

# âœ… JSON ë¡œë“œ ë° ë¬¸ì„œ ìƒì„±
with open(SOURCE_PATH, "r", encoding="utf-8") as f:
    data = json.load(f)

text = f"ê¸ˆê°• ë°±ì—”ë“œ êµ¬ì¡° ì„¤ëª…:\n{json.dumps(data, ensure_ascii=False, indent=2)}"
docs = [Document(page_content=text, metadata={"source": "backend_structure_natural"})]

# ğŸ”¢ ë¬¸ì„œ ë¶„í• 
splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=800, chunk_overlap=100)
split_docs = splitter.split_documents(docs)

# ğŸ’¾ ì €ì¥
db = Chroma.from_documents(split_docs, OpenAIEmbeddings(), persist_directory=CHROMA_PATH)
db.persist()
print("âœ… backend_structure_natural ì¸ê²ŒìŠ¤íŠ¸ ì™„ë£Œ")
