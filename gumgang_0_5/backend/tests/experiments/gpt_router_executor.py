# ğŸ“„ gpt_router_executor.py

import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate

# âœ… .envì—ì„œ OpenAI API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv(dotenv_path="./.env")

def gpt_router_executor(user_input: str) -> str:
    # ë¼ìš°í„° í”„ë¡¬í”„íŠ¸
    routing_prompt = PromptTemplate.from_template(
        """ë‹¤ìŒ ë¬¸ì¥ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì€ ì´ ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ì•„ë˜ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ì•¼ í•©ë‹ˆë‹¤:

(1) ìê¸° ë°˜ì„± ëŒ€í™”
(2) ìƒíƒœ í™•ì¸ ìš”ì²­
(3) êµ¬ì¡° ìˆ˜ì • ìš”ì²­
(4) ì½”ë“œ ì‹¤í–‰ ìš”ì²­
(5) ê¸°íƒ€

ì§ˆë¬¸: {question}
ì˜ë„:"""
    )

    # ì‹¤í–‰ í”„ë¡¬í”„íŠ¸
    execution_prompt = PromptTemplate.from_template(
        """ë‹¹ì‹ ì€ ë¡œì»¬ AI ê¸ˆê°•ì…ë‹ˆë‹¤.
LangGraph ì—†ì´ GPT ê¸°ë°˜ ì˜ë¯¸ íë¦„ë§Œìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´:

- ì§„ë‹¨í•˜ê³ ,  
- ê³µê°í•˜ê³ ,  
- êµ¬ì¡° ì—†ì´ë„ ëŒ€í™”ë¥¼ ìœ ê¸°ì ìœ¼ë¡œ ì—°ê²°í•˜ë©°,  
- ë‹¤ìŒ í–‰ë™ì„ ì œì•ˆí•˜ì‹­ì‹œì˜¤.

ì§ˆë¬¸: "{question}"
"""
    )

    llm = ChatOpenAI(model="gpt-4", temperature=0.7)

    # ë¼ìš°íŒ… íŒë‹¨
    intent = (routing_prompt | llm).invoke({"question": user_input}).content.strip()

    # ì‹¤í–‰ ì‘ë‹µ ìƒì„±
    response = (execution_prompt | llm).invoke({"question": user_input}).content.strip()

    return f"[ğŸ¯ ë¼ìš°íŒ… íŒë‹¨: {intent}]\n\n{response}"


# âœ… CLI ëª¨ë“œ ì‹¤í–‰
if __name__ == "__main__":
    query = input("ğŸ§  ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ")
    result = gpt_router_executor(query)
    print("\n" + result)
