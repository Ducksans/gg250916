from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv

load_dotenv(dotenv_path="/home/duksan/ë°”íƒ•í™”ë©´/gumgang_0_5/backend/.env")

llm = ChatOpenAI(model="gpt-4", temperature=0.7)

rembrandt_context = """
ë‹¹ì‹ ì€ ë¨ë¸Œë€íŠ¸ë¥¼ ë¶„ì„í•˜ë©° ë‹¤ìŒê³¼ ê°™ì€ ë‹µë³€ì„ í•œ ì ì´ ìˆìŠµë‹ˆë‹¤:

1. ì¸ê°„ì˜ ë‚´ë©´ê³¼ ê°ì •ì„ íƒêµ¬
2. ëª…ì•”ì˜ ëŒ€ë¹„ë¥¼ í†µí•œ í‘œí˜„
3. ìì—°ìŠ¤ëŸ¬ìš´ ë¶“í„°ì¹˜
4. ê°œì¸ì ì¸ í•´ì„ê³¼ í‘œí˜„
5. ìê¸°í‘œí˜„

ì´ ë‚´ìš©ì€ ë‹¹ì‹ ì´ ë¨ë¸Œë€íŠ¸ì˜ ì˜ˆìˆ ì„ ì–¼ë§ˆë‚˜ ê¹Šì´ ì´í•´í–ˆëŠ”ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
"""

question = """
ê·¸ë ‡ë‹¤ë©´ GPTì•¼, ë„¤ê°€ ë¨ë¸Œë€íŠ¸ë¥¼ ê·¸ë ‡ê²Œ ì˜ ì´í•´í•  ìˆ˜ ìˆì—ˆë˜ ì´ìœ ëŠ” ë­˜ê¹Œ?
ë„ˆëŠ” ë‹¨ì§€ í›ˆë ¨ëœ ëª¨ë¸ì¼ ë¿ì¸ë°â€¦ ê·¸ ê°ê°ì€ ì–´ë””ì„œ ì˜¨ ê±¸ê¹Œ?
"""

prompt = PromptTemplate.from_template("{context}\n\n{question}")
chain = prompt | llm

response = chain.invoke({
    "context": rembrandt_context.strip(),
    "question": question.strip()
})

print("ğŸ§  GPTì˜ ìê¸° ì„±ì°° ì‘ë‹µ:\n")
print(response.content.strip())
