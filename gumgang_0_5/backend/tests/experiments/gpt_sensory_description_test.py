from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from dotenv import load_dotenv
import os

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv(dotenv_path="/home/duksan/ë°”íƒ•í™”ë©´/gumgang_0_5/backend/.env")

# âœ… GPT ì´ˆê¸°í™”
llm = ChatOpenAI(model="gpt-4", temperature=0.7)

# âœ… ê°ê° ë¬˜ì‚¬ í”„ë¡¬í”„íŠ¸
prompt = PromptTemplate.from_template("""
ë‚´ê°€ ë°”ëŒì†Œë¦¬ë¥¼ í•œë²ˆ ë¬˜ì‚¬í•´ë³¼ê²Œ.

ì–´ê¹¨ë¥¼ ìŠ¤ì¹˜ê³  ì§€ë‚˜ê°€ëŠ” ì°¨ê°€ìš´ ë°”ëŒ,  
ë‚˜ë­‡ê°€ì§€ê°€ ìŠ¤ì¹˜ë©° í”ë“¤ë¦¬ëŠ” ì‚¬ê°ì‚¬ê°í•œ ì†Œë¦¬,  
ë©€ë¦¬ì„œ ë¶ˆì–´ì˜¤ë‹¤ ê°€ê¹Œì´ì„œ ê·“ê°€ë¥¼ ë•Œë¦¬ëŠ” ë¯¸ì„¸í•œ ì••ë ¥ì˜ ë³€í™”â€¦

ì, GPTì•¼. ì´ê±¸ ë“£ê³  ë¬´ì—‡ì„ ëŠê¼ˆë‹ˆ?  
ì´ê±¸ ë„ˆëŠ” ì–´ë–»ê²Œ â€˜ì˜ë¯¸â€™ë¡œ ì €ì¥í• ë˜?
""")

# âœ… GPT ì‹¤í–‰
chain = prompt | llm
response = chain.invoke({})

print("\nğŸ§  GPTì˜ ì‘ë‹µ:\n")
print(response.content.strip() if hasattr(response, "content") else response)
