# ğŸ“„ semantic_router_test.py

from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
import os
import sys

# âœ… .env ê²½ë¡œì—ì„œ OpenAI API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv(dotenv_path="/home/duksan/ë°”íƒ•í™”ë©´/gumgang_0_5/backend/.env")

llm = ChatOpenAI(model="gpt-4", temperature=0)

# âœ… ì§ˆë¬¸ ì˜ë¯¸ í•´ì„ìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
prompt = PromptTemplate.from_template("""
ë„ˆëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ í•´ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ëª…í™•í•˜ê²Œ ë°˜í™˜í•˜ëŠ” ì‹œìŠ¤í…œì´ì•¼.

ì§ˆë¬¸: "{question}"

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì˜ë„ë¥¼ ì¶”ë¡ í•´ì„œ ì¶œë ¥í•´ì¤˜:

{{
  "intent": "<í–‰ë™ ëª©ì >",
  "target": "<ëŒ€ìƒ íŒŒì¼, ì£¼ì œ, êµ¬ì¡° ë“±>",
  "timeframe": "<ì‹œê°„ ë²”ìœ„ ë˜ëŠ” null>",
  "confidence": <0.0~1.0>,
  "clarification_needed": <true ë˜ëŠ” false>
}}

ì§ˆë¬¸ì´ ëª¨í˜¸í•  ê²½ìš° clarification_neededë¥¼ trueë¡œ ì„¤ì •í•˜ê³ ,
"clarification_candidates" í•­ëª©ì„ ì•„ë˜ì²˜ëŸ¼ ì¶”ê°€í•´ì¤˜:

"clarification_candidates": ["ì˜ë„1", "ì˜ë„2", "ì˜ë„3"]
""")

def run_router(question: str):
    chain = prompt | llm
    result = chain.invoke({"question": question})
    print(result.content)

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("â— ì‚¬ìš©ë²•: python semantic_router_test.py \"ê¸ˆê°•ì•„, êµ¬ì¡° ì¢€ ë³´ì—¬ì¤˜\"")
    else:
        run_router(sys.argv[1])
