#!/usr/bin/env python3
"""
ê¸ˆê°• 2.0 ì„¸ì…˜ ê´€ë¦¬ ì‹œìŠ¤í…œ
- ì„¸ì…˜ ê°„ ì»¨í…ìŠ¤íŠ¸ ì˜ì†í™”
- í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€
- ì‹¤ì œ ìƒíƒœ ê¸°ë°˜ ì˜ì‚¬ê²°ì •
- 4ê³„ì¸µ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ

Author: Gumgang AI Team
Version: 2.0
Created: 2025-01-08
"""

import os
import json
import yaml
import hashlib
import subprocess
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict, field
import logging
import time

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/home/duksan/ë°”íƒ•í™”ë©´/gumgang_0_5/context/session.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
PROJECT_ROOT = Path("/home/duksan/ë°”íƒ•í™”ë©´/gumgang_0_5")

@dataclass
class FileState:
    """íŒŒì¼ ìƒíƒœ ì •ë³´"""
    path: str
    exists: bool
    size: int
    modified: str
    hash: Optional[str] = None
    content_preview: Optional[str] = None

@dataclass
class TaskInfo:
    """Task ì •ë³´"""
    task_id: str
    name: str
    status: str  # pending|in_progress|completed|failed
    progress: int
    created_at: str
    started_at: Optional[str] = None
    completed_at: Optional[str] = None
    parent_id: Optional[str] = None
    checkpoints: List[Dict] = field(default_factory=list)
    artifacts: List[str] = field(default_factory=list)

@dataclass
class SessionContext:
    """ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸"""
    session_id: str
    timestamp: str
    previous_session: Optional[str]
    verified_facts: Dict[str, Any]
    warnings: List[str]
    tasks_completed: List[TaskInfo]
    tasks_pending: List[TaskInfo]
    tasks_in_progress: List[TaskInfo]
    file_states: Dict[str, FileState]
    memory_layers: Dict[str, Dict]
    session_metrics: Dict[str, Any]

class SessionManager:
    """ì„¸ì…˜ ê´€ë¦¬ì - AIì™€ ì¸ê°„ì˜ í˜‘ì—…ì„ ìœ„í•œ í•µì‹¬ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.root = PROJECT_ROOT
        self.context_dir = self.root / "context"
        self.context_dir.mkdir(exist_ok=True)

        # ì»¨í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ
        self.current_context_file = self.context_dir / "current_session.yaml"
        self.history_file = self.context_dir / "session_history.json"
        self.file_registry = self.context_dir / "file_registry.json"
        self.task_registry = self.context_dir / "task_registry.json"

        # ë©”ëª¨ë¦¬ ê³„ì¸µ íŒŒì¼
        self.memory_layers = {
            "ultra_short": self.context_dir / "memory_ultra_short.json",  # í˜„ì¬ ì‘ì—…
            "short": self.context_dir / "memory_short.json",              # ì˜¤ëŠ˜ ì„¸ì…˜
            "medium": self.context_dir / "memory_medium.json",            # ì´ë²ˆ ì£¼
            "long": self.context_dir / "memory_long.json"                 # ì „ì²´ í”„ë¡œì íŠ¸
        }

        # Task ì¶”ì 
        self.current_task: Optional[TaskInfo] = None
        self.task_counter = 0

        logger.info("ì„¸ì…˜ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ")

    def generate_task_id(self, prefix: str = "GG") -> str:
        """Task ID ìƒì„±"""
        timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
        self.task_counter += 1
        return f"{prefix}-{timestamp}-{self.task_counter:03d}"

    def create_task(self, name: str, parent_id: Optional[str] = None) -> TaskInfo:
        """ìƒˆ Task ìƒì„±"""
        task = TaskInfo(
            task_id=self.generate_task_id(),
            name=name,
            status="pending",
            progress=0,
            created_at=datetime.now().isoformat(),
            parent_id=parent_id
        )

        logger.info(f"Task ìƒì„±: {task.task_id} - {name}")

        # Task ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ì €ì¥
        self._save_task_to_registry(task)

        return task

    def start_task(self, task: TaskInfo) -> TaskInfo:
        """Task ì‹œì‘"""
        task.status = "in_progress"
        task.started_at = datetime.now().isoformat()
        self.current_task = task

        logger.info(f"Task ì‹œì‘: {task.task_id} - {task.name}")

        # ì´ˆë‹¨ê¸° ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸
        self.update_memory("ultra_short", "current_task", {
            "task_id": task.task_id,
            "name": task.name,
            "started_at": task.started_at
        })

        return task

    def update_task_progress(self, task: TaskInfo, progress: int, checkpoint: Optional[str] = None):
        """Task ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸"""
        task.progress = min(100, max(0, progress))

        if checkpoint:
            task.checkpoints.append({
                "timestamp": datetime.now().isoformat(),
                "description": checkpoint,
                "progress": progress
            })

        logger.info(f"Task ì§„í–‰: {task.task_id} - {progress}% - {checkpoint}")

        # Task ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸
        self._save_task_to_registry(task)

    def complete_task(self, task: TaskInfo, artifacts: List[str] = None) -> TaskInfo:
        """Task ì™„ë£Œ"""
        task.status = "completed"
        task.progress = 100
        task.completed_at = datetime.now().isoformat()

        if artifacts:
            task.artifacts = artifacts

        logger.info(f"Task ì™„ë£Œ: {task.task_id} - {task.name}")
        logger.info(f"  ìƒì„±ëœ ì•„í‹°íŒ©íŠ¸: {artifacts}")

        # Task ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸
        self._save_task_to_registry(task)

        # í˜„ì¬ Task í•´ì œ
        if self.current_task and self.current_task.task_id == task.task_id:
            self.current_task = None

        return task

    def verify_project_structure(self) -> Dict[str, Any]:
        """í”„ë¡œì íŠ¸ êµ¬ì¡° ê²€ì¦ - í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€"""
        structure = {
            "timestamp": datetime.now().isoformat(),
            "directories": {},
            "critical_files": {},
            "issues": [],
            "recommendations": []
        }

        # ì£¼ìš” ë””ë ‰í† ë¦¬ í™•ì¸
        key_dirs = {
            "frontend_legacy": "frontend",
            "frontend_v2": "gumgang-v2",
            "backend": "backend",
            "memory": "memory",
            "context": "context",
            "task_tracking": "task_tracking"
        }

        for key, dir_name in key_dirs.items():
            dir_path = self.root / dir_name
            structure["directories"][key] = {
                "path": str(dir_path),
                "exists": dir_path.exists(),
                "is_dir": dir_path.is_dir() if dir_path.exists() else False,
                "file_count": len(list(dir_path.glob("**/*"))) if dir_path.exists() and dir_path.is_dir() else 0
            }

            if key == "frontend_legacy" and dir_path.exists():
                structure["issues"].append("âš ï¸ êµ¬ë²„ì „ frontend í´ë”ê°€ ì—¬ì „íˆ ì¡´ì¬í•©ë‹ˆë‹¤")
                structure["recommendations"].append("frontend í´ë”ë¥¼ legacy_backupìœ¼ë¡œ ì´ë™ í•„ìš”")

        # ì¤‘ìš” íŒŒì¼ í™•ì¸
        critical_files = [
            "gumgang-v2/package.json",
            "gumgang-v2/app/dashboard/page.tsx",
            "backend/app/api/routes/dashboard.py",
            "backend/main.py",
            "backend/app_new.py",
            "session_manager.py",
            "task_tracker.py"
        ]

        for file_path in critical_files:
            full_path = self.root / file_path
            if full_path.exists():
                stat = full_path.stat()
                structure["critical_files"][file_path] = {
                    "exists": True,
                    "size": stat.st_size,
                    "modified": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                    "hash": self._calculate_file_hash(full_path)
                }
            else:
                structure["critical_files"][file_path] = {"exists": False}

        return structure

    def check_running_services(self) -> Dict[str, Any]:
        """ì‹¤í–‰ ì¤‘ì¸ ì„œë¹„ìŠ¤ í™•ì¸"""
        services = {
            "frontend": {"port": 3000, "running": False, "process": None},
            "backend": {"port": 8000, "running": False, "process": None}
        }

        for service, info in services.items():
            try:
                result = subprocess.run(
                    ["lsof", "-i", f":{info['port']}"],
                    capture_output=True,
                    text=True,
                    timeout=5
                )
                if result.returncode == 0:
                    info["running"] = True
                    info["process"] = result.stdout.strip()[:100]  # ì²˜ìŒ 100ìë§Œ
            except Exception as e:
                logger.error(f"ì„œë¹„ìŠ¤ í™•ì¸ ì‹¤íŒ¨ {service}: {e}")

        return services

    def create_session(self, previous_session_id: Optional[str] = None) -> SessionContext:
        """ìƒˆ ì„¸ì…˜ ìƒì„±"""
        session_id = f"SESSION-{datetime.now().strftime('%Y%m%d-%H%M%S')}"

        # í”„ë¡œì íŠ¸ êµ¬ì¡° ê²€ì¦
        structure = self.verify_project_structure()
        services = self.check_running_services()

        # ì´ì „ ì„¸ì…˜ì—ì„œ Task ì •ë³´ ë¡œë“œ
        tasks_completed = []
        tasks_pending = []
        tasks_in_progress = []

        if previous_session_id:
            prev_context = self._load_session_from_history(previous_session_id)
            if prev_context:
                # ì™„ë£Œë˜ì§€ ì•Šì€ TaskëŠ” ì´ì›”
                tasks_pending = prev_context.get("tasks_pending", [])
                tasks_in_progress = prev_context.get("tasks_in_progress", [])

        # ì„¸ì…˜ ë©”íŠ¸ë¦­ ìƒì„±
        session_metrics = {
            "token_usage": {"current": 0, "limit": 120000},
            "api_calls": 0,
            "files_created": 0,
            "files_modified": 0,
            "execution_time": 0
        }

        # ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = SessionContext(
            session_id=session_id,
            timestamp=datetime.now().isoformat(),
            previous_session=previous_session_id,
            verified_facts={
                "structure": structure,
                "services": services,
                "frontend_path": "/gumgang-v2",
                "backend_path": "/backend",
                "using_next_js": True,
                "monaco_editor": True,
                "tauri_enabled": True
            },
            warnings=structure["issues"],
            tasks_completed=tasks_completed,
            tasks_pending=tasks_pending,
            tasks_in_progress=tasks_in_progress,
            file_states={},
            memory_layers={},
            session_metrics=session_metrics
        )

        # íŒŒì¼ ìƒíƒœ ê¸°ë¡
        for file_path, info in structure["critical_files"].items():
            if info["exists"]:
                context.file_states[file_path] = FileState(
                    path=file_path,
                    exists=True,
                    size=info.get("size", 0),
                    modified=info.get("modified", ""),
                    hash=info.get("hash", ""),
                    content_preview=self._get_file_preview(self.root / file_path)
                )

        # ì»¨í…ìŠ¤íŠ¸ ì €ì¥
        self.save_context(context)

        logger.info(f"ìƒˆ ì„¸ì…˜ ìƒì„±: {session_id}")
        logger.info(f"  ì´ì „ ì„¸ì…˜: {previous_session_id}")
        logger.info(f"  ëŒ€ê¸° Task: {len(tasks_pending)}ê°œ")
        logger.info(f"  ì§„í–‰ ì¤‘ Task: {len(tasks_in_progress)}ê°œ")

        return context

    def save_context(self, context: SessionContext):
        """ì»¨í…ìŠ¤íŠ¸ ì €ì¥"""
        # YAML í˜•ì‹ìœ¼ë¡œ í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ ì €ì¥
        context_dict = asdict(context)

        with open(self.current_context_file, 'w', encoding='utf-8') as f:
            yaml.dump(context_dict, f, allow_unicode=True, default_flow_style=False, sort_keys=False)

        # JSON í˜•ì‹ìœ¼ë¡œ íˆìŠ¤í† ë¦¬ ì¶”ê°€
        history = []
        if self.history_file.exists():
            try:
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    history = json.load(f)
            except:
                history = []

        # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€ (ìµœëŒ€ 100ê°œ ì„¸ì…˜ ìœ ì§€)
        history.append(context_dict)
        if len(history) > 100:
            history = history[-100:]

        with open(self.history_file, 'w', encoding='utf-8') as f:
            json.dump(history, f, indent=2, ensure_ascii=False)

        logger.info(f"ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ì €ì¥: {context.session_id}")

    def load_context(self) -> Optional[SessionContext]:
        """í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ"""
        if not self.current_context_file.exists():
            return None

        try:
            with open(self.current_context_file, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)

            # FileStateì™€ TaskInfo ê°ì²´ë¡œ ë³€í™˜
            file_states = {}
            for path, state_dict in data.get("file_states", {}).items():
                file_states[path] = FileState(**state_dict)

            tasks_completed = [TaskInfo(**t) for t in data.get("tasks_completed", [])]
            tasks_pending = [TaskInfo(**t) for t in data.get("tasks_pending", [])]
            tasks_in_progress = [TaskInfo(**t) for t in data.get("tasks_in_progress", [])]

            data["file_states"] = file_states
            data["tasks_completed"] = tasks_completed
            data["tasks_pending"] = tasks_pending
            data["tasks_in_progress"] = tasks_in_progress

            return SessionContext(**data)
        except Exception as e:
            logger.error(f"ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    def verify_file_exists(self, relative_path: str) -> Tuple[bool, Optional[Dict]]:
        """íŒŒì¼ ì¡´ì¬ ê²€ì¦ - ì¶”ì¸¡ ë°©ì§€"""
        full_path = self.root / relative_path
        exists = full_path.exists()

        info = {
            "path": relative_path,
            "exists": exists,
            "full_path": str(full_path)
        }

        if exists:
            stat = full_path.stat()
            info.update({
                "size": stat.st_size,
                "modified": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                "is_file": full_path.is_file(),
                "is_dir": full_path.is_dir()
            })
            logger.info(f"âœ… íŒŒì¼ í™•ì¸: {relative_path}")
        else:
            logger.warning(f"âŒ íŒŒì¼ ì—†ìŒ: {relative_path}")

            # ì»¨í…ìŠ¤íŠ¸ì— ê²½ê³  ì¶”ê°€
            context = self.load_context()
            if context:
                warning = f"íŒŒì¼ ì—†ìŒ: {relative_path} ({datetime.now().strftime('%H:%M:%S')})"
                if warning not in context.warnings:
                    context.warnings.append(warning)
                    self.save_context(context)

        return exists, info

    def update_memory(self, layer: str, key: str, value: Any):
        """ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸"""
        if layer not in self.memory_layers:
            raise ValueError(f"Unknown memory layer: {layer}")

        memory_file = self.memory_layers[layer]
        memory = {}

        if memory_file.exists():
            try:
                with open(memory_file, 'r', encoding='utf-8') as f:
                    memory = json.load(f)
            except:
                memory = {}

        memory[key] = {
            "value": value,
            "timestamp": datetime.now().isoformat(),
            "session_id": self.load_context().session_id if self.load_context() else "unknown"
        }

        with open(memory_file, 'w', encoding='utf-8') as f:
            json.dump(memory, f, indent=2, ensure_ascii=False)

        logger.info(f"ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸: {layer}/{key}")

    def get_memory(self, layer: str, key: str = None) -> Any:
        """ë©”ëª¨ë¦¬ ì¡°íšŒ"""
        if layer not in self.memory_layers:
            raise ValueError(f"Unknown memory layer: {layer}")

        memory_file = self.memory_layers[layer]
        if not memory_file.exists():
            return None if key else {}

        try:
            with open(memory_file, 'r', encoding='utf-8') as f:
                memory = json.load(f)

            if key:
                return memory.get(key, {}).get("value")
            return memory
        except:
            return None if key else {}

    def create_checkpoint(self, name: str, description: str = "") -> Dict[str, Any]:
        """ì²´í¬í¬ì¸íŠ¸ ìƒì„±"""
        checkpoint_id = f"CP-{datetime.now().strftime('%Y%m%d-%H%M%S')}"

        checkpoint = {
            "id": checkpoint_id,
            "name": name,
            "description": description,
            "timestamp": datetime.now().isoformat(),
            "session_id": self.load_context().session_id if self.load_context() else None,
            "current_task": asdict(self.current_task) if self.current_task else None,
            "memory_snapshot": {
                "ultra_short": self.get_memory("ultra_short"),
                "short": self.get_memory("short")
            }
        }

        # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì €ì¥
        checkpoint_file = self.context_dir / f"checkpoint_{checkpoint_id}.json"
        with open(checkpoint_file, 'w', encoding='utf-8') as f:
            json.dump(checkpoint, f, indent=2, ensure_ascii=False)

        logger.info(f"ì²´í¬í¬ì¸íŠ¸ ìƒì„±: {checkpoint_id} - {name}")

        return checkpoint

    def _calculate_file_hash(self, file_path: Path) -> str:
        """íŒŒì¼ í•´ì‹œ ê³„ì‚°"""
        if not file_path.exists() or not file_path.is_file():
            return ""

        try:
            hasher = hashlib.md5()
            with open(file_path, 'rb') as f:
                # í° íŒŒì¼ì„ ìœ„í•´ ì²­í¬ ë‹¨ìœ„ë¡œ ì½ê¸°
                for chunk in iter(lambda: f.read(65536), b''):
                    hasher.update(chunk)

            return hasher.hexdigest()
        except:
            return ""

    def _get_file_preview(self, file_path: Path, lines: int = 5) -> str:
        """íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°"""
        if not file_path.exists() or not file_path.is_file():
            return ""

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                preview_lines = []
                for i, line in enumerate(f):
                    if i >= lines:
                        break
                    preview_lines.append(line.rstrip())
                return '\n'.join(preview_lines)
        except:
            return ""

    def _save_task_to_registry(self, task: TaskInfo):
        """Taskë¥¼ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ì €ì¥"""
        registry = {}
        if self.task_registry.exists():
            try:
                with open(self.task_registry, 'r', encoding='utf-8') as f:
                    registry = json.load(f)
            except:
                registry = {}

        registry[task.task_id] = asdict(task)

        with open(self.task_registry, 'w', encoding='utf-8') as f:
            json.dump(registry, f, indent=2, ensure_ascii=False)

    def _load_session_from_history(self, session_id: str) -> Optional[Dict]:
        """íˆìŠ¤í† ë¦¬ì—ì„œ íŠ¹ì • ì„¸ì…˜ ë¡œë“œ"""
        if not self.history_file.exists():
            return None

        try:
            with open(self.history_file, 'r', encoding='utf-8') as f:
                history = json.load(f)

            for session in history:
                if session.get("session_id") == session_id:
                    return session
        except:
            pass

        return None

    def generate_status_report(self) -> str:
        """ìƒíƒœ ë³´ê³ ì„œ ìƒì„±"""
        context = self.load_context()
        if not context:
            return "ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."

        structure = self.verify_project_structure()
        services = self.check_running_services()

        report = f"""
# ê¸ˆê°• 2.0 ì„¸ì…˜ ìƒíƒœ ë³´ê³ ì„œ
ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ì„¸ì…˜ ì •ë³´
- ì„¸ì…˜ ID: {context.session_id}
- ì‹œì‘ ì‹œê°„: {context.timestamp}
- ì´ì „ ì„¸ì…˜: {context.previous_session or 'ì—†ìŒ'}

## Task í˜„í™©
- ì™„ë£Œ: {len(context.tasks_completed)}ê°œ
- ì§„í–‰ ì¤‘: {len(context.tasks_in_progress)}ê°œ
- ëŒ€ê¸°: {len(context.tasks_pending)}ê°œ

## í˜„ì¬ Task
"""

        if self.current_task:
            report += f"""
- ID: {self.current_task.task_id}
- ì´ë¦„: {self.current_task.name}
- ìƒíƒœ: {self.current_task.status}
- ì§„í–‰ë¥ : {self.current_task.progress}%
"""
        else:
            report += "- ì‹¤í–‰ ì¤‘ì¸ Task ì—†ìŒ\n"

        report += f"""
## ì„œë¹„ìŠ¤ ìƒíƒœ
- Frontend (í¬íŠ¸ 3000): {'ğŸŸ¢ ì‹¤í–‰ ì¤‘' if services['frontend']['running'] else 'ğŸ”´ ì¤‘ì§€'}
- Backend (í¬íŠ¸ 8000): {'ğŸŸ¢ ì‹¤í–‰ ì¤‘' if services['backend']['running'] else 'ğŸ”´ ì¤‘ì§€'}

## í”„ë¡œì íŠ¸ êµ¬ì¡°
"""

        for key, info in structure["directories"].items():
            status = "âœ…" if info["exists"] else "âŒ"
            report += f"- {status} {key}: {info['path']}\n"

        if context.warnings:
            report += "\n## âš ï¸ ê²½ê³ \n"
            for warning in context.warnings:
                report += f"- {warning}\n"

        return report


def main():
    """í…ŒìŠ¤íŠ¸ ë° ì´ˆê¸° ì„¤ì •"""
    print("ğŸš€ ê¸ˆê°• 2.0 ì„¸ì…˜ ë§¤ë‹ˆì € ì´ˆê¸°í™”")
    print("="*50)

    manager = SessionManager()

    # ìƒˆ ì„¸ì…˜ ìƒì„±
    context = manager.create_session()

    # Task ìƒì„± ë° ì‹¤í–‰ ì˜ˆì œ
    task = manager.create_task("ì„¸ì…˜ ë§¤ë‹ˆì € ì‹œìŠ¤í…œ êµ¬ì¶•")
    manager.start_task(task)
    manager.update_task_progress(task, 25, "ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ì™„ë£Œ")

    # ìƒíƒœ ë³´ê³ ì„œ ì¶œë ¥
    print(manager.generate_status_report())

    print("\nâœ… ì„¸ì…˜ ë§¤ë‹ˆì € ì¤€ë¹„ ì™„ë£Œ!")
    print(f"ğŸ“ ì»¨í…ìŠ¤íŠ¸ ìœ„ì¹˜: {manager.context_dir}")
    print(f"ğŸ“‹ í˜„ì¬ ì„¸ì…˜: {context.session_id}")


if __name__ == "__main__":
    main()
