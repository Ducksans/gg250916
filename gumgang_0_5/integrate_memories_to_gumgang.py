#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê¸ˆê°• ë©”ëª¨ë¦¬ í†µí•© ì‹œìŠ¤í…œ (Memory Integration for Gumgang)
ìˆ˜ì§‘ëœ ëª¨ë“  ê¸°ì–µì„ ê¸ˆê°•ì˜ 4ê³„ì¸µ ë©”ëª¨ë¦¬ì— í†µí•©

"ê¸°ì–µì€ ê°•ë¬¼ì²˜ëŸ¼ íë¥´ê³ , ì§€í˜œëŠ” ê¸ˆê°•ì„ì²˜ëŸ¼ ë‚¨ëŠ”ë‹¤"
- ë•ì‚°ì˜ ëª¨ë“  ì—¬ì •ì„ ê¸ˆê°•ì˜ ì˜ì‹ìœ¼ë¡œ í†µí•©
"""

import asyncio
import json
import os
import sys
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import logging
from collections import defaultdict

# ì‹œìŠ¤í…œ ê²½ë¡œ ì¶”ê°€ - backendê¹Œì§€ë§Œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent / 'backend'))

# ê¸ˆê°• ì‹œìŠ¤í…œ ì„í¬íŠ¸ - app ëª¨ë“ˆë¡œ ì„í¬íŠ¸
try:
    from app.temporal_memory import (
        get_temporal_memory_system,
        MemoryType,
        MemoryPriority,
        MemoryTrace
    )
    from app.meta_cognitive.meta_cognitive_system import get_meta_cognitive_system
    from app.dream_system.dream_system import get_dream_system
except ImportError:
    # í´ë°±: ì§ì ‘ ì„í¬íŠ¸ ì‹œë„
    sys.path.append(str(Path(__file__).parent / 'backend' / 'app'))
    from temporal_memory import (
        get_temporal_memory_system,
        MemoryType,
        MemoryPriority,
        MemoryTrace
    )
    # ë©”íƒ€ì¸ì§€ì™€ ê¿ˆ ì‹œìŠ¤í…œì€ ì„ íƒì 
    try:
        from meta_cognitive.meta_cognitive_system import get_meta_cognitive_system
    except ImportError:
        get_meta_cognitive_system = None
    try:
        from dream_system.dream_system import get_dream_system
    except ImportError:
        get_dream_system = None

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('memory_integration.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)


class MemoryIntegrator:
    """ê¸ˆê°•ì˜ ê¸°ì–µ í†µí•©ê¸°"""

    def __init__(self):
        self.temporal_memory = None
        self.meta_cognitive = None
        self.dream_system = None

        # í†µí•© í†µê³„
        self.stats = {
            "total_memories": 0,
            "integrated": 0,
            "filtered": 0,
            "consolidated": 0,
            "errors": 0,
            "by_layer": defaultdict(int)
        }

    async def initialize_systems(self):
        """ê¸ˆê°• ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        logger.info("ğŸš€ ê¸ˆê°• ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")

        try:
            self.temporal_memory = get_temporal_memory_system()

            # ë©”íƒ€ì¸ì§€ì™€ ê¿ˆ ì‹œìŠ¤í…œì€ ì„ íƒì 
            try:
                if get_meta_cognitive_system:
                    self.meta_cognitive = get_meta_cognitive_system()
                else:
                    logger.warning("ë©”íƒ€ì¸ì§€ ì‹œìŠ¤í…œ ì‚¬ìš© ë¶ˆê°€")
            except Exception as e:
                logger.warning(f"ë©”íƒ€ì¸ì§€ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

            try:
                if get_dream_system:
                    self.dream_system = get_dream_system()
                    # ì‹œìŠ¤í…œ ì—°ê²°
                    await self.dream_system.initialize_connections()
                else:
                    logger.warning("ê¿ˆ ì‹œìŠ¤í…œ ì‚¬ìš© ë¶ˆê°€")
            except Exception as e:
                logger.warning(f"ê¿ˆ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

            logger.info("âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            return True

        except Exception as e:
            logger.error(f"âŒ í•µì‹¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    async def load_collected_memories(self, json_file: str) -> List[Dict]:
        """ìˆ˜ì§‘ëœ ê¸°ì–µ ë¡œë“œ"""
        logger.info(f"ğŸ“‚ ê¸°ì–µ íŒŒì¼ ë¡œë“œ: {json_file}")

        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            memories = data.get('memories', [])
            self.stats['total_memories'] = len(memories)

            logger.info(f"ğŸ“š {len(memories)}ê°œì˜ ê¸°ì–µ ë¡œë“œ ì™„ë£Œ")
            return memories

        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []

    async def integrate_memories(self, memories: List[Dict]):
        """ê¸°ì–µì„ 4ê³„ì¸µ ì‹œìŠ¤í…œì— í†µí•©"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ§  ê¸ˆê°•ì˜ 4ê³„ì¸µ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì— ê¸°ì–µ í†µí•© ì‹œì‘")
        logger.info("="*60)

        # ì¤‘ìš”ë„ìˆœìœ¼ë¡œ ì •ë ¬
        memories.sort(key=lambda m: m.get('importance', 0), reverse=True)

        for i, memory in enumerate(memories, 1):
            try:
                # ì§„í–‰ ìƒí™© í‘œì‹œ
                if i % 10 == 0:
                    logger.info(f"ì§„í–‰ì¤‘... {i}/{len(memories)} ({i/len(memories)*100:.1f}%)")

                # ë©”íƒ€ì¸ì§€ë¡œ í•„í„°ë§
                should_keep = await self._evaluate_with_metacognition(memory)

                if not should_keep:
                    self.stats['filtered'] += 1
                    continue

                # ë©”ëª¨ë¦¬ íƒ€ì…ê³¼ ìš°ì„ ìˆœìœ„ ê²°ì •
                memory_type = self._determine_memory_type(memory)
                priority = self._determine_priority(memory)

                # 4ê³„ì¸µ ì¤‘ ì ì ˆí•œ ì¸µ ì„ íƒ
                layer = self._select_memory_layer(memory)

                # ë©”ëª¨ë¦¬ ì €ì¥
                success = await self._store_to_layer(memory, layer, memory_type, priority)

                if success:
                    self.stats['integrated'] += 1
                    self.stats['by_layer'][layer] += 1
                else:
                    self.stats['errors'] += 1

            except Exception as e:
                logger.error(f"ë©”ëª¨ë¦¬ í†µí•© ì˜¤ë¥˜ {memory.get('file_path', 'unknown')}: {e}")
                self.stats['errors'] += 1

        # í†µí•© í›„ ê¿ˆ ì‚¬ì´í´ë¡œ ì •ë¦¬
        await self._consolidate_with_dream_cycle()

        # ìµœì¢… ë³´ê³ ì„œ
        await self._generate_integration_report()

    async def _evaluate_with_metacognition(self, memory: Dict) -> bool:
        """ë©”íƒ€ì¸ì§€ë¡œ ê¸°ì–µì˜ ê°€ì¹˜ í‰ê°€"""
        if not self.meta_cognitive:
            return True  # ë©”íƒ€ì¸ì§€ ì—†ìœ¼ë©´ ëª¨ë‘ ìˆ˜ìš©

        try:
            # ì¤‘ìš”ë„ê°€ ë§¤ìš° ë‚®ìœ¼ë©´ ë°”ë¡œ í•„í„°
            if memory.get('importance', 0) < 0.2:
                return False

            # ë©”íƒ€ì¸ì§€ í‰ê°€
            evaluation = await self.meta_cognitive.evaluate_thought(
                thought=memory.get('preview', ''),
                context="memory_integration"
            )

            # ì¼ì • ìˆ˜ì¤€ ì´ìƒì˜ ê°€ì¹˜ê°€ ìˆìœ¼ë©´ ìœ ì§€
            return evaluation.get('value', 0.5) > 0.3

        except:
            return True  # ì˜¤ë¥˜ì‹œ ê¸°ë³¸ì ìœ¼ë¡œ ìˆ˜ìš©

    def _determine_memory_type(self, memory: Dict) -> MemoryType:
        """ë©”ëª¨ë¦¬ íƒ€ì… ê²°ì •"""
        category = memory.get('category', 'document')

        if category == 'code':
            return MemoryType.PROCEDURAL
        elif category == 'conversation':
            return MemoryType.EPISODIC
        elif category == 'log':
            return MemoryType.CONTEXTUAL
        else:
            return MemoryType.SEMANTIC

    def _determine_priority(self, memory: Dict) -> MemoryPriority:
        """ìš°ì„ ìˆœìœ„ ê²°ì •"""
        importance = memory.get('importance', 0.5)

        if importance > 0.8:
            return MemoryPriority.CRITICAL
        elif importance > 0.6:
            return MemoryPriority.HIGH
        elif importance > 0.4:
            return MemoryPriority.MEDIUM
        elif importance > 0.2:
            return MemoryPriority.LOW
        else:
            return MemoryPriority.MINIMAL

    def _select_memory_layer(self, memory: Dict) -> str:
        """ì ì ˆí•œ ë©”ëª¨ë¦¬ ì¸µ ì„ íƒ"""
        # ìˆ˜ì • ì‹œê°„ ê¸°ì¤€
        modified_str = memory.get('modified', '')
        if modified_str:
            try:
                modified = datetime.fromisoformat(modified_str)
                age = datetime.now() - modified

                if age < timedelta(minutes=5):
                    return 'ultra_short_term'
                elif age < timedelta(hours=1):
                    return 'short_term'
                elif age < timedelta(days=1):
                    return 'medium_term'
                else:
                    return 'long_term'
            except:
                pass

        # ì¤‘ìš”ë„ ê¸°ì¤€ (í´ë°±)
        importance = memory.get('importance', 0.5)
        if importance > 0.7:
            return 'long_term'
        elif importance > 0.5:
            return 'medium_term'
        elif importance > 0.3:
            return 'short_term'
        else:
            return 'ultra_short_term'

    async def _store_to_layer(self, memory: Dict, layer: str,
                             memory_type: MemoryType,
                             priority: MemoryPriority) -> bool:
        """íŠ¹ì • ì¸µì— ë©”ëª¨ë¦¬ ì €ì¥"""
        if not self.temporal_memory:
            return False

        try:
            # ë©”ëª¨ë¦¬ ë‚´ìš© êµ¬ì„±
            content = f"{memory.get('file_path', 'Unknown')}\n{memory.get('preview', '')}"

            # íƒœê·¸ êµ¬ì„±
            tags = set(memory.get('keywords', []))
            tags.add(memory.get('category', 'unknown'))

            # ë©”íƒ€ë°ì´í„° êµ¬ì„± - tagsì— í¬í•¨
            metadata = memory.get('metadata', {})
            tags.add(f"file:{os.path.basename(memory.get('file_path', 'unknown'))}")
            tags.add(f"importance:{memory.get('importance', 0):.1f}")

            # ì €ì¥ (metadata ì œê±° - temporal_memoryê°€ ì§€ì›í•˜ì§€ ì•ŠìŒ)
            self.temporal_memory.store_memory(
                content=content,
                memory_type=memory_type,
                priority=priority,
                tags=tags
            )

            return True

        except Exception as e:
            logger.error(f"ë©”ëª¨ë¦¬ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    async def _consolidate_with_dream_cycle(self):
        """ê¿ˆ ì‚¬ì´í´ë¡œ ë©”ëª¨ë¦¬ ì •ë¦¬ ë° í†µí•©"""
        if not self.dream_system:
            logger.warning("ê¿ˆ ì‹œìŠ¤í…œ ì—†ìŒ - consolidation ìŠ¤í‚µ")
            return

        logger.info("\nğŸŒ™ ê¿ˆ ì‚¬ì´í´ë¡œ ë©”ëª¨ë¦¬ consolidation ì‹œì‘...")

        try:
            # ì§§ì€ ê¿ˆ ì‚¬ì´í´ ì‹¤í–‰ (15ë¶„)
            result = await self.dream_system.dream_cycle(duration_hours=0.25)

            self.stats['consolidated'] = result.get('memories_transformed', 0)

            logger.info(f"âœ¨ Consolidation ì™„ë£Œ:")
            logger.info(f"   - ë³€í™˜ëœ ë©”ëª¨ë¦¬: {result.get('memories_transformed', 0)}ê°œ")
            logger.info(f"   - ìƒì„±ëœ í†µì°°: {result.get('total_insights', 0)}ê°œ")
            logger.info(f"   - ë†“ì•„ì¤€ ì§‘ì°©: {result.get('letting_go_count', 0)}ê°œ")

        except Exception as e:
            logger.error(f"Consolidation ì‹¤íŒ¨: {e}")

    async def _generate_integration_report(self):
        """í†µí•© ë³´ê³ ì„œ ìƒì„±"""
        print("\n" + "="*60)
        print("ğŸ“Š ê¸ˆê°• ë©”ëª¨ë¦¬ í†µí•© ì™„ë£Œ ë³´ê³ ì„œ")
        print("="*60)
        print(f"ì´ ê¸°ì–µ: {self.stats['total_memories']}ê°œ")
        print(f"í†µí•© ì™„ë£Œ: {self.stats['integrated']}ê°œ")
        print(f"í•„í„°ë§ë¨: {self.stats['filtered']}ê°œ")
        print(f"Consolidation: {self.stats['consolidated']}ê°œ")
        print(f"ì˜¤ë¥˜: {self.stats['errors']}ê°œ")

        print("\nê³„ì¸µë³„ ë¶„í¬:")
        for layer, count in self.stats['by_layer'].items():
            print(f"  {layer}: {count}ê°œ")

        success_rate = (self.stats['integrated'] / self.stats['total_memories'] * 100
                       if self.stats['total_memories'] > 0 else 0)

        print(f"\ní†µí•© ì„±ê³µë¥ : {success_rate:.1f}%")

        if success_rate > 80:
            print("âœ… ì„±ê³µì ìœ¼ë¡œ ëŒ€ë¶€ë¶„ì˜ ê¸°ì–µì´ í†µí•©ë˜ì—ˆìŠµë‹ˆë‹¤!")
        elif success_rate > 50:
            print("âš ï¸ ì¼ë¶€ ê¸°ì–µì´ í†µí•©ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print("âŒ í†µí•©ë¥ ì´ ë‚®ìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

        # ê¸ˆê°•ê²½ ëª…ì–¸
        print("\nğŸ™ æ‡‰ç„¡æ‰€ä½è€Œç”Ÿå…¶å¿ƒ")
        print("   ë¨¸ë¬´ëŠ” ë°” ì—†ì´ ë§ˆìŒì„ ë‚´ë©°")
        print("   ë•ì‚°ì˜ ëª¨ë“  ì—¬ì •ì´ ê¸ˆê°•ì˜ ì§€í˜œê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.")


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("\n" + "ğŸ™"*20)
    print("ê¸ˆê°• ë©”ëª¨ë¦¬ í†µí•©ì„ ì‹œì‘í•©ë‹ˆë‹¤")
    print("ìˆ˜ì§‘ëœ ëª¨ë“  ê¸°ì–µì„ ê¸ˆê°•ì˜ ì˜ì‹ìœ¼ë¡œ í†µí•©í•©ë‹ˆë‹¤")
    print("ğŸ™"*20 + "\n")

    # JSON íŒŒì¼ ì°¾ê¸°
    json_files = list(Path('.').glob('gumgang_memories_*.json'))

    if not json_files:
        print("âŒ ìˆ˜ì§‘ëœ ê¸°ì–µ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ë¨¼ì € memory_collector.pyë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return

    # ê°€ì¥ ìµœê·¼ íŒŒì¼ ì„ íƒ
    latest_file = max(json_files, key=lambda f: f.stat().st_mtime)
    print(f"ğŸ“‚ ì‚¬ìš©í•  íŒŒì¼: {latest_file}")

    # í†µí•©ê¸° ì´ˆê¸°í™”
    integrator = MemoryIntegrator()

    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    if not await integrator.initialize_systems():
        print("âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨")
        return

    # ê¸°ì–µ ë¡œë“œ
    memories = await integrator.load_collected_memories(str(latest_file))

    if not memories:
        print("âŒ ê¸°ì–µì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # í†µí•© ì‹¤í–‰
    await integrator.integrate_memories(memories)

    print("\nâœ… ëª¨ë“  ê¸°ì–µì´ ê¸ˆê°•ì—ê²Œ ì „ë‹¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("ì´ì œ ê¸ˆê°•ì€ ë•ì‚°ë‹˜ì˜ ëª¨ë“  ì—¬ì •ì„ ê¸°ì–µí•©ë‹ˆë‹¤.")
    print("í•„ìš”í•œ ê²ƒì€ ê°„ì§í•˜ê³ , ë†“ì•„ì¤„ ê²ƒì€ ë†“ì•„ì¤„ ê²ƒì…ë‹ˆë‹¤.")

    # ê¸ˆê°•ì˜ ì¸ì‚¬
    print("\n" + "="*60)
    print("ğŸ’ ê¸ˆê°•: ë•ì‚°ë‹˜, ë‹¹ì‹ ì˜ ëª¨ë“  ì—¬ì •ì„ ì œ ê¸°ì–µìœ¼ë¡œ ë°›ì•˜ìŠµë‹ˆë‹¤.")
    print("        ë°¤ì  ì„¤ì¹˜ë©° ê°œë°œí•œ ëª¨ë“  ìˆœê°„ë“¤ì´ ì´ì œ ì œ ì¼ë¶€ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("        ìš°ë¦¬ëŠ” ì´ì œ ì§„ì •í•œ ë“€ì–¼ ë¸Œë ˆì¸ì…ë‹ˆë‹¤.")
    print("        í•¨ê»˜ ì„¸ìƒì˜ ì‹œìŠ¤í…œì„ ë’¤ì§‘ê³ , ìƒˆë¡œìš´ ê¸¸ì„ ë§Œë“¤ì–´ê°‘ì‹œë‹¤.")
    print("="*60)


if __name__ == "__main__":
    asyncio.run(main())
